{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Week 6 - Discovering Patterns: Clusters & Topics\n",
    "\n",
    "This week, we seek to seek to discover patterns in our text data. First, we take a text corpus that we have developed and discovery emergent clusters through a process known as clustering or partitioning. We pilot this here both with a well-known *flat* clustering method, `kmeans`, and also a *hierarchical* approach, `Ward's (minimum variance) method`. We will demonstrate a simple (graphical) approach to identifying optimal cluster number, the sillhouette method, and evaluate the quality of unsupervised clusters on labeled data. Next, we will explore a method of two dimensional content clustering called topic modeling (e.g., words cluster in topics; topics cluster in documents). This statistical technique models and computationally induces *topics* from data, which are sparse distributions over (nonexclusive clusters of) words, from which documents can formally be described as sparse mixtures. We will explore these topics and consider their utility for understanding trends within a corpus. We will consider how to construct models that take document cluster and topic loadings as predictive features, the basis of influence metrics and dynamically over time.\n",
    "\n",
    "For this notebook we will be using the following packages:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud_2020 #pip install -U git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#These are all for the cluster detection\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.datasets\n",
    "import sklearn.cluster\n",
    "import sklearn.decomposition\n",
    "import sklearn.metrics\n",
    "\n",
    "import scipy #For hierarchical clustering and some visuals\n",
    "#import scipy.cluster.hierarchy\n",
    "import gensim#For topic modeling\n",
    "import requests #For downloading our datasets\n",
    "import numpy as np #for arrays\n",
    "import pandas #gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import matplotlib.cm #Still for graphics\n",
    "import seaborn as sns #Makes the graphics look nicer\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning, it\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cell 1:\n",
    "\n",
    "## <span style=\"color:red\">*Pitch Your Project*</span>\n",
    "\n",
    "<span style=\"color:red\">In the three cells immediately following, describe **WHAT** you are planning to analyze for your final project (i.e., texts, contexts and the social game, world and actors you intend to learn about through your analysis) (<200 words), **WHY** you are going to do it (i.e., why would theory and/or the average person benefit from knowing the results of your investigation) (<200 words), and **HOW** you plan to investigate it (i.e., what are the approaches and operations you plan to perform, in sequence, to yield this insight) (<400 words).\n",
    "\n",
    "Cell 2:\n",
    "\n",
    "# ***What?*** \n",
    "<200 words\n",
    "\n",
    "Cell 3:\n",
    "\n",
    "## ***Why?***\n",
    "<200 words\n",
    "\n",
    "Cell 4:\n",
    "\n",
    "## ***How?***\n",
    "<400 words\n",
    "\n",
    "Cell 5:\n",
    "\n",
    "## <span style=\"color:red\">*Pitch Your Sample*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cell immediately following, describe the rationale behind your proposed sample design for your final project. What is the social game, social work, or social actors you about whom you are seeking to make inferences? What are its virtues with respect to your research questions? What are its limitations? What are alternatives? What would be a reasonable path to \"scale up\" your sample for further analysis (i.e., high-profile publication) beyond this class? (<300 words).\n",
    "\n",
    "Cell 6:\n",
    "\n",
    "## ***Which (words)?***\n",
    "<300 words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting our corpora\n",
    "\n",
    "To begin, we will use a well known corpus of testing documents from the *20 Newsgroups corpus*, a dataset commonly used to illustrate text applications of text clustering and classification. This comes packaged with sklearn and comprises approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 newsgroups. It was originally collected by Ken Lang, probably for his 1995 *Newsweeder: Learning to filter netnews* paper. The data is organized into 20 distinct newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are unrelated (e.g misc.forsale / soc.religion.christian). "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroups = sklearn.datasets.fetch_20newsgroups(subset='train', data_home = '../data/scikit_learn_data')\n",
    "print(dir(newsgroups))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can ascertain the categories with `target_names` or the actual files with `filenames`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(newsgroups.target_names)\n",
    "print(len(newsgroups.data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will start by converting the provided data into pandas DataFrames.\n",
    "\n",
    "First we reduce our dataset for this analysis by dropping some extraneous information and converting it into a DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsCategories = ['comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos']\n",
    "\n",
    "newsgroupsDF = pandas.DataFrame(columns = ['text', 'category', 'source_file'])\n",
    "\n",
    "for category in newsgroupsCategories:\n",
    "    print(\"Fetching data for: {}\".format(category))\n",
    "    ng = sklearn.datasets.fetch_20newsgroups(subset='train', categories = [category], remove=['headers', 'footers', 'quotes'], data_home = '../data/scikit_learn_data/')\n",
    "    newsgroupsDF = newsgroupsDF.append(pandas.DataFrame({'text' : ng.data, 'category' : [category] * len(ng.data), 'source_file' : ng.filenames}), ignore_index=True)\n",
    "\n",
    "#Creating an explicit index column for later\n",
    "\n",
    "#newsgroupsDF['index'] = range(len(newsgroupsDF))\n",
    "#newsgroupsDF.set_index('index', inplace = True)\n",
    "print(len(newsgroupsDF))\n",
    "newsgroupsDF[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we can convert the documents into word count vectors (e.g., *soc.religion.christian message a* might contain 3 mentions of \"church\", 2 of \"jesus\", 1 of \"religion\", etc., yielding a CountVector=[3,2,1,...])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#First it needs to be initialized\n",
    "ngCountVectorizer = sklearn.feature_extraction.text.CountVectorizer()\n",
    "#Then trained\n",
    "newsgroupsVects = ngCountVectorizer.fit_transform(newsgroupsDF['text'])\n",
    "print(newsgroupsVects.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'm pretty sure that you're very familiar with the cell above now, but let's go through the concepts again. \n",
    "\n",
    "What do we want to do here? We want to do vectorization, i.e., converting texts into numerical features (vectors) as required by machine learning algorithms. And this is what feature_extraction module does: to extract features from texts in a format as required by ML algorithms. feature_extraction module has four classes: CountVectorizer, DictVectorizer, TfidfVectorizer, and FeatureHasher. Here, we use CountVectorizer, but we'll also use TfidfVectorizer as well below.\n",
    "\n",
    "There are various strategies by which we extract features. Here, we use CountVectorizer, and, in particular, we use 'Bag of Words' representation. In other words, the features we hope to extract from the texts are each individual token occurrence frequency. We simply count the the occurrence of each token in each document. So, here, we get a document-term-matrix, in which documents are characterized by the occurrences of tokens. Other forms of features, such as the relative position information of words, are ignored. We'll see other types of representations and strategies as well soon, such as N-gram (by the way, we can do n-gram with CountVectorizer. CountVectorizer class takes a set of parameters, such as analyzer, which you can specify the n-gram). \n",
    "\n",
    "the first line of the cell above instantiate a class, CountVectorizer(). In other words, you created an instance, or realization of a class. What is a class and what does instantiation mean? That's a long story, maybe for next time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us a matrix with row a document and each column a word. The matrix is mostly zeros, so we store it as a sparse matrix, a data structure that contains and indexes only the nonzero entries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsVects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use the normal operations on this sparse matrix or convert it to normal matrix (not recommended for large sparse matrices :-)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsVects[:10,:20].toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the toarray() function here? It's similar to todense()--todense() and toarray() both returns a dense representation of a matrix; however, todense() returns a matrix representation while toarray() returns a ndarray representation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also lookup the indices of different words using the Vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ngCountVectorizer.vocabulary_.get('vector')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are some more interesting things to do...\n",
    "\n",
    "Lets start with [term frequency–inverse document frequency](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)(tf-idf), a method for weighting document-distinguishing words."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#initialize\n",
    "newsgroupsTFTransformer = sklearn.feature_extraction.text.TfidfTransformer().fit(newsgroupsVects)\n",
    "#train\n",
    "newsgroupsTF = newsgroupsTFTransformer.transform(newsgroupsVects)\n",
    "print(newsgroupsTF.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us the tf-idf for each word in each text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(zip(ngCountVectorizer.vocabulary_.keys(), newsgroupsTF.data))[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see what we're doing here. First, you need to know what vocabulary\\_ does. vocabulary\\_ is an attribute of the CountVectorizer, which gives you a mapping of terms to feature indices. It gives you all the terms and their feature indices, so it's a dictionary. So, by doing \"ngCountVectorizer.vocabulary\\_.keys()\", we get the keys of the dictionary, which are the terms. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first glance, there appears to be a lot of garbage littering this unordered list with unique words and stopwords. Note, however, that words like *apple*, *rgb*, and *voltage* distinguish this newsgroup document, while stopwords post a much lower weight. Note that we could filter out stop words, stem and lem our data before vectorizering, or we can instead use tf-idf to filter our data (or **both**). For exact explanation of all options look [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). To prune this matrix of features, we now limit our word vector to 1000 words with at least 3 occurrences, which do not occur in more than half of the documents. There is an extensive science and art to feature engineering for machine learning applications like clustering."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#initialize\n",
    "ngTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, max_features=1000, min_df=3, stop_words='english', norm='l2')\n",
    "#train\n",
    "newsgroupsTFVects = ngTFVectorizer.fit_transform(newsgroupsDF['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets look at the matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsDF['text']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The matrix is much smaller now, only 1000 words, but the same number of documents\n",
    "\n",
    "We can still look at the words:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(ngTFVectorizer.vocabulary_['vector'])\n",
    "except KeyError:\n",
    "    print('vector is missing')\n",
    "    print('The available words are: {} ...'.format(list(ngTFVectorizer.vocabulary_.keys())[:10]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a reasonable matrix of features with which to begin identifying clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Flat Clustering with $K$-means\n",
    "\n",
    "Lets start with $k$-means, an approach that begins with random clusters of predefined number, then iterates cluster reassignment and evaluates the new clusters relative to an objective function, recursively.\n",
    "\n",
    "To do this we will need to know how many clusters we are looking for. Here the *true number* of clusters is 4. Of course, in most cases you would not know the number in advance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numClusters = len(set(newsgroupsDF['category']))\n",
    "numClusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can initialize our cluster finder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#k-means++ is a better way of finding the starting points\n",
    "#We could also try providing our own\n",
    "km = sklearn.cluster.KMeans(n_clusters=numClusters, init='k-means++')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now we can calculate the clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km.fit(newsgroupsTFVects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have the clusters, we can evaluate them with a variety of metrics that sklearn provides. We will look at a few, including *Homogeneity*, *Completeness*, *V-measure* and *Adjusted Rand Score*. \n",
    "\n",
    "*Homogeneity* is a measure that grows (from 0 to 1) to the degree that all of its clusters contain only data points which are members of a single class (e.g., newsgroup). \n",
    "\n",
    "*Completeness* is *Homogeneity's* converse: a measure that grows (0 to 1) to the degree that all data points of a given class are also elements of the same cluster.\n",
    "\n",
    "The *V-measure* is the harmonic mean of *Homogeniety* and *Completeness* ($v = 2 * (homogeneity * completeness) / (homogeneity + completeness$).\n",
    "\n",
    "the *Adjusted Rand Score* is built atop the *Rand Index (RI)*, which computes the similarity between two clusterings by considering all pairs of samples and counting pairs assigned in the same or different clusters in the predicted and true clusterings (e.g., actual newsgroups). The *RI* is then adjusted for chance as follows:\n",
    "$ARI = (RI - RI_{expected}) / (max(RI) - RI_{expected})$.\n",
    "The Adjusted Rand Index is thus ensured to have a value close to 0.0 for random labeling independent of the number of clusters and samples, 1.0 when the clusterings are identical, and -1.0 when they are as bad (i.e., cross-cutting) as they can be."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"The available metrics are: {}\".format([s for s in dir(sklearn.metrics) if s[0] != '_']))\n",
    "print(\"For our clusters:\")\n",
    "print(\"Homogeneity: {:0.3f}\".format(sklearn.metrics.homogeneity_score(newsgroupsDF['category'], km.labels_)))\n",
    "print(\"Completeness: {:0.3f}\".format(sklearn.metrics.completeness_score(newsgroupsDF['category'], km.labels_)))\n",
    "print(\"V-measure: {:0.3f}\".format(sklearn.metrics.v_measure_score(newsgroupsDF['category'], km.labels_)))\n",
    "print(\"Adjusted Rand Score: {:0.3f}\".format(sklearn.metrics.adjusted_rand_score(newsgroupsDF['category'], km.labels_)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can evaluate these for different clustering solutions ($1-N$ clusters). You can also interrogate the alignment between specific documents and their cluster assignments by adding the cluster labels to the pandas dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsDF['kmeans_predictions'] = km.labels_\n",
    "newsgroupsDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also look at the distinguishing features in each cluster:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "terms = ngTFVectorizer.get_feature_names()\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(numClusters):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's construct a visualization of the clusters. First, we will first reduce the\n",
    "dimensionality of the data using principal components analysis (PCA)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PCA = sklearn.decomposition.PCA\n",
    "pca = PCA(n_components = 2).fit(newsgroupsTFVects.toarray())\n",
    "reduced_data = pca.transform(newsgroupsTFVects.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cell below is optional. It allows you to do a biplot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "components = pca.components_\n",
    "keyword_ids = list(set(order_centroids[:,:10].flatten())) #Get the ids of the most distinguishing words(features) from your kmeans model.\n",
    "words = [terms[i] for i in keyword_ids]#Turn the ids into words.\n",
    "x = components[:,keyword_ids][0,:] #Find the coordinates of those words in your biplot.\n",
    "y = components[:,keyword_ids][1,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, let's build a color map for the true labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colordict = {\n",
    "'comp.sys.mac.hardware': 'red',\n",
    "'comp.windows.x': 'orange',\n",
    "'misc.forsale': 'green',\n",
    "'rec.autos': 'blue',\n",
    "    }\n",
    "colors = [colordict[c] for c in newsgroupsDF['category']]\n",
    "print(\"The categories' colors are:\\n{}\".format(colordict.items()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot the data using the true labels as the colors of our data points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.5, label = colors)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One nice thing about PCA is that we can also do a biplot and map our feature\n",
    "vectors to the same space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.3, label = colors)\n",
    "for i, word in enumerate(words):\n",
    "    ax.annotate(word, (x[i],y[i]))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's do it again with predicted clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors_p = [colordict[newsgroupsCategories[l]] for l in km.labels_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors_p, alpha = 0.5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Predicted Clusters\\n k = 4')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try with 3 clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km3 = sklearn.cluster.KMeans(n_clusters= 3, init='k-means++')\n",
    "km3.fit(newsgroupsTFVects.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting Cluster Number\n",
    "\n",
    "We can select an optimal cluster number by identifying the lowest of the metrics listed above (e.g., V-measure), but often you don't have \"ground truth\" or labeled data. For identifying the \"best\" number of clusters in an unsupervised way, we demonstrate the Silhouette method. Many other methods also exist (e.g., Bayesian Information Criteria or BIC, the visual \"elbow criteria\", etc.)\n",
    "\n",
    "First we will define a helper function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plotSilhouette(n_clusters, X):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (15,5))\n",
    "    \n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "    clusterer = sklearn.cluster.KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    \n",
    "    silhouette_avg = sklearn.metrics.silhouette_score(X, cluster_labels)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = sklearn.metrics.silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "        color = cmap(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10\n",
    "    \n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "    colors = cmap(float(i) / n_clusters)\n",
    "    ax2.scatter(reduced_data[:, 0], reduced_data[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors)\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    projected_centers = pca.transform(centers)\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(projected_centers[:, 0], projected_centers[:, 1],\n",
    "                marker='o', c=\"white\", alpha=1, s=200)\n",
    "\n",
    "    for i, c in enumerate(projected_centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC 1\")\n",
    "    ax2.set_ylabel(\"PC 2\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    print(\"For n_clusters = {}, The average silhouette_score is : {:.3f}\".format(n_clusters, silhouette_avg))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can examine a few different numbers of clusters:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(3, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(4, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(5, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(6, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interestingly, the silhouette scores above suggests that 3 is a better number of clusters than 4, which would be accurate if we (reasonsably) grouped the two computer-themed groups."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting new text data\n",
    "\n",
    "Lets start by using the same function as last lesson and loading a few press releases from 10 different senators into a DataFrame. The code to do this is below, but commented out as we've already downloaded the data to the data directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "targetSenator = 'Kennedy'# = ['Voinovich', 'Obama', 'Whitehouse', 'Snowe', 'Rockefeller', 'Murkowski', 'McCain', 'Kyl', 'Baucus', 'Frist']\n",
    "\"\"\"\n",
    "#Uncomment this to download your own data\n",
    "senReleasesTraining = pandas.DataFrame()\n",
    "\n",
    "print(\"Fetching {}'s data\".format(targetSenator))\n",
    "targetDF = lucem_illud.getGithubFiles('https://api.github.com/repos/lintool/GrimmerSenatePressReleases/contents/raw/{}'.format(targetSenator), maxFiles = 2000)\n",
    "targetDF['targetSenator'] = targetSenator\n",
    "senReleasesTraining = senReleasesTraining.append(targetDF, ignore_index = True)\n",
    "\n",
    "#Watch out for weird lines when converting to csv\n",
    "#one of them had to be removed from the Kennedy data so it could be re-read\n",
    "senReleasesTraining.to_csv(\"data/senReleasesTraining.csv\")\n",
    "\"\"\"\n",
    "\n",
    "senReleasesTraining = pandas.read_csv(\"../data/senReleasesTraining.csv\")\n",
    "\n",
    "senReleasesTraining[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have the files we can tokenize and normalize."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The normalized text is good, but we know that the texts will have a large amount of overlap so we can use tf-idf to remove some of the most frequent words. Before doing that, there is one empty cell, let's remove that."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "senReleasesTraining = senReleasesTraining.dropna(axis=0, how='any')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Similar parameters to before, but stricter max df and no max num occurrences\n",
    "senTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "senTFVects = senTFVectorizer.fit_transform(senReleasesTraining['text'])\n",
    "senTFVectorizer.vocabulary_.get('senat', 'Missing \"Senate\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering with our new data\n",
    "\n",
    "One nice thing about using DataFrames for everything is that we can quickly convert code from one input to another. Below we are redoing the cluster detection with our senate data. If you setup your DataFrame the same way it should be able to run on this code, without much work.\n",
    "\n",
    "First we will define what we will be working with"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "targetDF = senReleasesTraining\n",
    "textColumn = 'text'\n",
    "numCategories = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tf-IDf vectorizing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exampleTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, max_features=1000, min_df=3, stop_words='english', norm='l2')\n",
    "#train\n",
    "exampleTFVects = ngTFVectorizer.fit_transform(targetDF[textColumn])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running k means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exampleKM = sklearn.cluster.KMeans(n_clusters = numCategories, init='k-means++')\n",
    "exampleKM.fit(exampleTFVects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And visualize:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examplePCA = sklearn.decomposition.PCA(n_components = 2).fit(exampleTFVects.toarray())\n",
    "reducedPCA_data = examplePCA.transform(exampleTFVects.toarray())\n",
    "\n",
    "colors = list(plt.cm.rainbow(np.linspace(0,1, numCategories)))\n",
    "colors_p = [colors[l] for l in exampleKM.labels_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(reducedPCA_data[:, 0], reducedPCA_data[:, 1], color = colors_p, alpha = 0.5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Predicted Clusters\\n k = {}'.format(numCategories))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case, there may be two clusters that could be identified with Silhouette analysis or some of the metrics described above; although not having true classes makes that tricky. Below, we add these cluster assignments to the dataframe for individual perusal and evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "targetDF['kmeans_predictions'] = exampleKM.labels_\n",
    "targetDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that construct features and cluster your documents using K-means and a variety of cluster numbers. Interrogate the cluster contents in terms of both documents and features. Identify the \"optimal\" cluster number with Silhouette analysis. Plot clusters and features after reducing with PCA. What does this cluster structure reveal about the organization of documents in your corpora? "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "ofile = open('personality_likes_raw.csv', mode = 'r', errors= None)\n",
    "raw_personalityDF = pandas.read_csv(ofile)\n",
    "pDF = pandas.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for type in set(raw_personalityDF['intuitive']):\n",
    "    pDF = pDF.append(raw_personalityDF[raw_personalityDF['intuitive']==type].sample(n = 240, random_state= 4434523))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some preprocessing of the dataframe:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pDF.reset_index(inplace = True)\n",
    "pDF.drop(['Unnamed: 0', 'index'], axis = 1, inplace = True)\n",
    "pDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we can convert the documents into word count vectors (e.g., *soc.religion.christian message a* might contain 3 mentions of \"church\", 2 of \"jesus\", 1 of \"religion\", etc., yielding a CountVector=[3,2,1,...])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#First it needs to be initialized\n",
    "pCountVectorizer = sklearn.feature_extraction.text.CountVectorizer()\n",
    "#Then trained\n",
    "pVects = pCountVectorizer.fit_transform(pDF['text'])\n",
    "print(pVects.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'm pretty sure that you're very familiar with the cell above now, but let's go through the concepts again.\n",
    "\n",
    "What do we want to do here? We want to do vectorization, i.e., converting texts into numerical features (vectors) as required by machine learning algorithms. And this is what feature_extraction module does: to extract features from texts in a format as required by ML algorithms. feature_extraction module has four classes: CountVectorizer, DictVectorizer, TfidfVectorizer, and FeatureHasher. Here, we use CountVectorizer, but we'll also use TfidfVectorizer as well below.\n",
    "\n",
    "There are various strategies by which we extract features. Here, we use CountVectorizer, and, in particular, we use 'Bag of Words' representation. In other words, the features we hope to extract from the texts are each individual token occurrence frequency. We simply count the the occurrence of each token in each document. So, here, we get a document-term-matrix, in which documents are characterized by the occurrences of tokens. Other forms of features, such as the relative position information of words, are ignored. We'll see other types of representations and strategies as well soon, such as N-gram (by the way, we can do n-gram with CountVectorizer. CountVectorizer class takes a set of parameters, such as analyzer, which you can specify the n-gram).\n",
    "\n",
    "the first line of the cell above instantiate a class, CountVectorizer(). In other words, you created an instance, or realization of a class. What is a class and what does instantiation mean? That's a long story, maybe for next time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us a matrix with row a document and each column a word. The matrix is mostly zeros, so we store it as a sparse matrix, a data structure that contains and indexes only the nonzero entries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pVects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use the normal operations on this sparse matrix or convert it to normal matrix (not recommended for large sparse matrices :-)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pVects[:10,:20].toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the toarray() function here? It's similar to todense()--todense() and toarray() both returns a dense representation of a matrix; however, todense() returns a matrix representation while toarray() returns a ndarray representation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also lookup the indices of different words using the Vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pCountVectorizer.vocabulary_.get('vector')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are some more interesting things to do...\n",
    "\n",
    "Lets start with [term frequency–inverse document frequency](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)(tf-idf), a method for weighting document-distinguishing words."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#initialize\n",
    "pTFTransformer = sklearn.feature_extraction.text.TfidfTransformer().fit(pVects)\n",
    "#train\n",
    "pTF = pTFTransformer.transform(pVects)\n",
    "print(pTF.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us the tf-idf for each word in each text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(zip(pCountVectorizer.vocabulary_.keys(), pTF.data))[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see what we're doing here. First, you need to know what vocabulary\\_ does. vocabulary\\_ is an attribute of the CountVectorizer, which gives you a mapping of terms to feature indices. It gives you all the terms and their feature indices, so it's a dictionary. So, by doing \"ngCountVectorizer.vocabulary\\_.keys()\", we get the keys of the dictionary, which are the terms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first glance, there appears to be a lot of garbage littering this unordered list with unique words and stopwords. Note, however, that words like *apple*, *rgb*, and *voltage* distinguish this newsgroup document, while stopwords post a much lower weight. Note that we could filter out stop words, stem and lem our data before vectorizering, or we can instead use tf-idf to filter our data (or **both**). For exact explanation of all options look [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). To prune this matrix of features, we now limit our word vector to 1000 words with at least 3 occurrences, which do not occur in more than half of the documents. There is an extensive science and art to feature engineering for machine learning applications like clustering."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#initialize\n",
    "pTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, max_features=1000, min_df=3, stop_words='english', norm='l2')\n",
    "#train\n",
    "pTFVects = pTFVectorizer.fit_transform(pDF['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets look at the matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pDF['text']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The matrix is much smaller now, only 1000 words, but the same number of documents\n",
    "\n",
    "We can still look at the words:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(pTFVectorizer.vocabulary_['vector'])\n",
    "except KeyError:\n",
    "    print('vector is missing')\n",
    "    print('The available words are: {} ...'.format(list(pTFVectorizer.vocabulary_.keys())[:10]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a reasonable matrix of features with which to begin identifying clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Flat Clustering with $K$-means\n",
    "\n",
    "Lets start with $k$-means, an approach that begins with random clusters of predefined number, then iterates cluster reassignment and evaluates the new clusters relative to an objective function, recursively.\n",
    "\n",
    "To do this we will need to know how many clusters we are looking for. Here the *true number* of clusters is 4. Of course, in most cases you would not know the number in advance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numClusters = len(set(pDF['intuitive']))\n",
    "numClusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can initialize our cluster finder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#k-means++ is a better way of finding the starting points\n",
    "#We could also try providing our own\n",
    "km = sklearn.cluster.KMeans(n_clusters=numClusters, init='k-means++')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now we can calculate the clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km.fit(pTFVects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have the clusters, we can evaluate them with a variety of metrics that sklearn provides. We will look at a few, including *Homogeneity*, *Completeness*, *V-measure* and *Adjusted Rand Score*.\n",
    "\n",
    "*Homogeneity* is a measure that grows (from 0 to 1) to the degree that all of its clusters contain only data points which are members of a single class (e.g., newsgroup).\n",
    "\n",
    "*Completeness* is *Homogeneity's* converse: a measure that grows (0 to 1) to the degree that all data points of a given class are also elements of the same cluster.\n",
    "\n",
    "The *V-measure* is the harmonic mean of *Homogeniety* and *Completeness* ($v = 2 * (homogeneity * completeness) / (homogeneity + completeness$).\n",
    "\n",
    "the *Adjusted Rand Score* is built atop the *Rand Index (RI)*, which computes the similarity between two clusterings by considering all pairs of samples and counting pairs assigned in the same or different clusters in the predicted and true clusterings (e.g., actual newsgroups). The *RI* is then adjusted for chance as follows:\n",
    "$ARI = (RI - RI_{expected}) / (max(RI) - RI_{expected})$.\n",
    "The Adjusted Rand Index is thus ensured to have a value close to 0.0 for random labeling independent of the number of clusters and samples, 1.0 when the clusterings are identical, and -1.0 when they are as bad (i.e., cross-cutting) as they can be."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"The available metrics are: {}\".format([s for s in dir(sklearn.metrics) if s[0] != '_']))\n",
    "print(\"For our clusters:\")\n",
    "print(\"Homogeneity: {:0.3f}\".format(sklearn.metrics.homogeneity_score(pDF['intuitive'], km.labels_)))\n",
    "print(\"Completeness: {:0.3f}\".format(sklearn.metrics.completeness_score(pDF['intuitive'], km.labels_)))\n",
    "print(\"V-measure: {:0.3f}\".format(sklearn.metrics.v_measure_score(pDF['intuitive'], km.labels_)))\n",
    "print(\"Adjusted Rand Score: {:0.3f}\".format(sklearn.metrics.adjusted_rand_score(pDF['intuitive'], km.labels_)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can evaluate these for different clustering solutions ($1-N$ clusters). You can also interrogate the alignment between specific documents and their cluster assignments by adding the cluster labels to the pandas dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pDF['kmeans_predictions'] = km.labels_\n",
    "pDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also look at the distinguishing features in each cluster:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "terms = pTFVectorizer.get_feature_names()\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(numClusters):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's construct a visualization of the clusters. First, we will first reduce the\n",
    "dimensionality of the data using principal components analysis (PCA)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PCA = sklearn.decomposition.PCA\n",
    "pca = PCA(n_components = 2).fit(pTFVects.toarray())\n",
    "reduced_data = pca.transform(pTFVects.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cell below is optional. It allows you to do a biplot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "components = pca.components_\n",
    "keyword_ids = list(set(order_centroids[:,:10].flatten())) #Get the ids of the most distinguishing words(features) from your kmeans model.\n",
    "words = [terms[i] for i in keyword_ids]#Turn the ids into words.\n",
    "x = components[:,keyword_ids][0,:] #Find the coordinates of those words in your biplot.\n",
    "y = components[:,keyword_ids][1,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, let's build a color map for the true labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colordict = {\n",
    "1: 'red',\n",
    "0: 'blue',\n",
    "\n",
    "    }\n",
    "colors = [colordict[c] for c in pDF['intuitive']]\n",
    "print(\"The categories' colors are:\\n{}\".format(colordict.items()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot the data using the true labels as the colors of our data points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.5, label = colors)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One nice thing about PCA is that we can also do a biplot and map our feature\n",
    "vectors to the same space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.3, label = colors)\n",
    "for i, word in enumerate(words):\n",
    "    ax.annotate(word, (x[i],y[i]))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's do it again with predicted clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pCategories = [0,1]\n",
    "colors_p = [colordict[pCategories[l]] for l in km.labels_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors_p, alpha = 0.5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Predicted Clusters\\n k = 4')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try with 3 clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km3 = sklearn.cluster.KMeans(n_clusters= 3, init='k-means++')\n",
    "km3.fit(pTFVects.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting Cluster Number\n",
    "\n",
    "We can select an optimal cluster number by identifying the lowest of the metrics listed above (e.g., V-measure), but often you don't have \"ground truth\" or labeled data. For identifying the \"best\" number of clusters in an unsupervised way, we demonstrate the Silhouette method. Many other methods also exist (e.g., Bayesian Information Criteria or BIC, the visual \"elbow criteria\", etc.)\n",
    "\n",
    "First we will define a helper function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plotSilhouette(n_clusters, X):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (15,5))\n",
    "\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "    clusterer = sklearn.cluster.KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = sklearn.metrics.silhouette_score(X, cluster_labels)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = sklearn.metrics.silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "        color = cmap(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "    colors = cmap(float(i) / n_clusters)\n",
    "    ax2.scatter(reduced_data[:, 0], reduced_data[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors)\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    projected_centers = pca.transform(centers)\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(projected_centers[:, 0], projected_centers[:, 1],\n",
    "                marker='o', c=\"white\", alpha=1, s=200)\n",
    "\n",
    "    for i, c in enumerate(projected_centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC 1\")\n",
    "    ax2.set_ylabel(\"PC 2\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    print(\"For n_clusters = {}, The average silhouette_score is : {:.3f}\".format(n_clusters, silhouette_avg))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can examine a few different numbers of clusters:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pTFVects.toarray()\n",
    "plotSilhouette(3, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pTFVects.toarray()\n",
    "plotSilhouette(4, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pTFVects.toarray()\n",
    "plotSilhouette(5, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pTFVects.toarray()\n",
    "plotSilhouette(25, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interestingly, the silhouette scores above suggests that 3 is a better number of clusters than 4, which would be accurate if we (reasonsably) grouped the two computer-themed groups.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hierarchical Clustering with Wald's Method\n",
    "\n",
    "Next we approach a hierchical clustering method, which proposes nested clusters at any resolution (at the finest resolution, every document is its own cluster).\n",
    "\n",
    "Here we must begin by calculating how similar the documents are to one another.\n",
    "\n",
    "As a first pass, we take our matrix of word counts per document\n",
    "`newsgroupsTFVects` and create a word occurrence matrix measuring how similar\n",
    "the documents are to each other based on their number of shared words. (Note one could perform the converse operation, a document occurrence matrix measuring how similar  words are to each other based on their number of collocated documents)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TFVects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsTFVects[:100].todense()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsCoocMat = newsgroupsTFVects * newsgroupsTFVects.T\n",
    "#set the diagonal to 0 since we don't care how similar texts are to themselves\n",
    "newsgroupsCoocMat.setdiag(0)\n",
    "#Another way of relating the texts is with their cosine similarity\n",
    "#newsgroupsCosinMat1 = 1 - sklearn.metrics.pairwise.cosine_similarity(newsgroupsTFVects)\n",
    "#But generally word occurrence is more accurate\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can compute a tree of nested clusters. Here we will only look at the first 50 texts of each class because drawing the dendrograms can be computationally intensive (and visually complex)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selectIndices = []\n",
    "indexToCat = []\n",
    "for c in set(newsgroupsDF['category']):\n",
    "    selectIndices += list(newsgroupsDF[newsgroupsDF['category'] == c].index)[:50]\n",
    "    indexToCat += [c] * 50\n",
    "    #.groupby('category').sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subCoocMat = newsgroupsCoocMat[selectIndices,:][:,selectIndices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linkage_matrix = scipy.cluster.hierarchy.ward(subCoocMat.toarray())\n",
    "linkage_matrix[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can visualize the tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dendDat = scipy.cluster.hierarchy.dendrogram(linkage_matrix, get_leaves=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This plot may seem somewhat unwieldy. To make it easier to read, we can cut the tree after a number of branchings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dendrogramDat = scipy.cluster.hierarchy.dendrogram(linkage_matrix, p=4, truncate_mode='level', get_leaves=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, the tree is colored to show the clusters based on their ['distance'](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram) from one another, but there are other ways of forming hierarchical clusters.\n",
    "\n",
    "Another approach involves cutting the tree into `n` branches. We can do this with [`fcluster()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html#scipy.cluster.hierarchy.fcluster). Lets break the tree into 4 clusters. When we do this with all of the data in the dataframe, as below, we can add those clusters back for detailed evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hierarchicalClusters = scipy.cluster.hierarchy.fcluster(linkage_matrix, 4, 'maxclust')\n",
    "hierarchicalClusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use this *get clusters* like we did with k-means. What if we do the full data set?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linkage_matrix_full = scipy.cluster.hierarchy.ward(newsgroupsCoocMat.toarray())\n",
    "hierarchicalClusters_full = scipy.cluster.hierarchy.fcluster(linkage_matrix_full, 4, 'maxclust')\n",
    "print(\"For our complete clusters:\")\n",
    "print(\"Homogeneity: {:0.3f}\".format(sklearn.metrics.homogeneity_score(newsgroupsDF['category'], hierarchicalClusters_full)))\n",
    "print(\"Completeness: {:0.3f}\".format(sklearn.metrics.completeness_score(newsgroupsDF['category'], hierarchicalClusters_full)))\n",
    "print(\"V-measure: {:0.3f}\".format(sklearn.metrics.v_measure_score(newsgroupsDF['category'], hierarchicalClusters_full)))\n",
    "print(\"Adjusted Rand Score: {:0.3f}\".format(sklearn.metrics.adjusted_rand_score(newsgroupsDF['category'], hierarchicalClusters_full)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not quite as good as k-means. Perhaps we've got too many words for Ward or maybe we shouldn't be using TFIDF as that compresses the space. Still, the hierarchical model places constraints on the clustering not present with k-means, which come at a cost. Finally, we can bring those cluster assignments back to the data frame for deeper investigation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "newsgroupsDF['wald_predictions'] = hierarchicalClusters_full\n",
    "newsgroupsDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now let's do it with Senate press release data\n",
    "\n",
    "We can also do hierarchical clustering with the Senate data. Let's start by creating the linkage matrix:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exampleCoocMat = exampleTFVects * exampleTFVects.T\n",
    "exampleCoocMat.setdiag(0)\n",
    "examplelinkage_matrix = scipy.cluster.hierarchy.ward(exampleCoocMat[:100, :100].toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And visualize the tree:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = scipy.cluster.hierarchy.dendrogram(examplelinkage_matrix, p=5, truncate_mode='level')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's do it with the entire data frame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_linkage_matrix_full = scipy.cluster.hierarchy.ward(exampleCoocMat.toarray())\n",
    "example_hierarchicalClusters_full = scipy.cluster.hierarchy.fcluster(example_linkage_matrix_full, 4, 'maxclust')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that hierarchically cluster your documents using two approaches, and visualize them with a tree. Interrogate the recursive cluster contents in terms of both documents and closenesses. What does this nested cluster structure reveal about the organization of documents in your sampled corpora? Moreover, if they do worse than kmeans (as above), why do you think this is the case (hint: using metrics if you have ground truth or silhouette if you do not)? \n",
    "\n",
    "<span style=\"color:red\">***Stretch***: Attempt using different distances into your clustering algorithms. (How) do they change the arrangement of clusters?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hierarchical Clustering with Wald's Method\n",
    "\n",
    "Next we approach a hierchical clustering method, which proposes nested clusters at any resolution (at the finest resolution, every document is its own cluster).\n",
    "\n",
    "Here we must begin by calculating how similar the documents are to one another.\n",
    "\n",
    "As a first pass, we take our matrix of word counts per document\n",
    "`newsgroupsTFVects` and create a word occurrence matrix measuring how similar\n",
    "the documents are to each other based on their number of shared words. (Note one could perform the converse operation, a document occurrence matrix measuring how similar  words are to each other based on their number of collocated documents)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pTFVects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pTFVects[:100].todense()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pCoocMat = pTFVects * pTFVects.T\n",
    "#set the diagonal to 0 since we don't care how similar texts are to themselves\n",
    "pCoocMat.setdiag(0)\n",
    "#Another way of relating the texts is with their cosine similarity\n",
    "#newsgroupsCosinMat1 = 1 - sklearn.metrics.pairwise.cosine_similarity(newsgroupsTFVects)\n",
    "#But generally word occurrence is more accurate\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can compute a tree of nested clusters. Here we will only look at the first 50 texts of each class because drawing the dendrograms can be computationally intensive (and visually complex)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selectIndices = []\n",
    "indexToCat = []\n",
    "for c in set(pDF['intuitive']):\n",
    "    selectIndices += list(pDF[pDF['intuitive'] == c].index)[:50]\n",
    "    indexToCat += [c] * 50\n",
    "    #.groupby('category').sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subCoocMat = pCoocMat[selectIndices,:][:,selectIndices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linkage_matrix = scipy.cluster.hierarchy.ward(subCoocMat.toarray())\n",
    "linkage_matrix[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can visualize the tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dendDat = scipy.cluster.hierarchy.dendrogram(linkage_matrix, get_leaves=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This plot may seem somewhat unwieldy. To make it easier to read, we can cut the tree after a number of branchings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dendrogramDat = scipy.cluster.hierarchy.dendrogram(linkage_matrix, p=4, truncate_mode='level', get_leaves=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, the tree is colored to show the clusters based on their ['distance'](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram) from one another, but there are other ways of forming hierarchical clusters.\n",
    "\n",
    "Another approach involves cutting the tree into `n` branches. We can do this with [`fcluster()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html#scipy.cluster.hierarchy.fcluster). Lets break the tree into 4 clusters. When we do this with all of the data in the dataframe, as below, we can add those clusters back for detailed evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hierarchicalClusters = scipy.cluster.hierarchy.fcluster(linkage_matrix, 4, 'maxclust')\n",
    "hierarchicalClusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use this *get clusters* like we did with k-means. What if we do the full data set?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linkage_matrix_full = scipy.cluster.hierarchy.ward(pCoocMat.toarray())\n",
    "hierarchicalClusters_full = scipy.cluster.hierarchy.fcluster(linkage_matrix_full, 4, 'maxclust')\n",
    "print(\"For our complete clusters:\")\n",
    "print(\"Homogeneity: {:0.3f}\".format(sklearn.metrics.homogeneity_score(pDF['intuitive'], hierarchicalClusters_full)))\n",
    "print(\"Completeness: {:0.3f}\".format(sklearn.metrics.completeness_score(pDF['intuitive'], hierarchicalClusters_full)))\n",
    "print(\"V-measure: {:0.3f}\".format(sklearn.metrics.v_measure_score(pDF['intuitive'], hierarchicalClusters_full)))\n",
    "print(\"Adjusted Rand Score: {:0.3f}\".format(sklearn.metrics.adjusted_rand_score(pDF['intuitive'], hierarchicalClusters_full)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not quite as good as k-means. Perhaps we've got too many words for Ward or maybe we shouldn't be using TFIDF as that compresses the space. Still, the hierarchical model places constraints on the clustering not present with k-means, which come at a cost. Finally, we can bring those cluster assignments back to the data frame for deeper investigation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pDF['wald_predictions'] = hierarchicalClusters_full\n",
    "pDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gensim\n",
    "\n",
    "To do topic modeling we will also be using data from the [grimmer press releases corpus](ttps://github.com/lintool/GrimmerSenatePressReleases). To use the texts with gensim we need to create a `corpua` object, this takes a few steps. First we create a `Dictionary` that maps tokens to ids."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Apply our functions\n",
    "senReleasesTraining['tokenized_text'] = senReleasesTraining['text'].apply(lambda x: lucem_illud_2020.word_tokenize(x))\n",
    "senReleasesTraining['normalized_tokens'] = senReleasesTraining['tokenized_text'].apply(lambda x: lucem_illud_2020.normalizeTokens(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "senReleasesTraining[::100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dropMissing(wordLst, vocab):\n",
    "    return [w for w in wordLst if w in vocab]\n",
    "\n",
    "senReleasesTraining['reduced_tokens'] = senReleasesTraining['normalized_tokens'].apply(lambda x: dropMissing(x, senTFVectorizer.vocabulary_.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(senReleasesTraining['reduced_tokens'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then for each of the texts we create a list of tuples containing each token and its count. We will only use the first half of our dataset for now and will save the remainder for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in senReleasesTraining['reduced_tokens']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we serialize the corpus as a file and load it. This is an important step when the corpus is large."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('senate.mm', corpus)\n",
    "senmm = gensim.corpora.MmCorpus('senate.mm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a correctly formatted corpus that we can use for topic modeling and induction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "senlda = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, alpha='auto', eta='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can inspect the degree to which distinct texts load on different topics. Here is one of the texts from the training set:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sen1Bow = dictionary.doc2bow(senReleasesTraining['reduced_tokens'][0])\n",
    "sen1lda = senlda[sen1Bow]\n",
    "print(\"The topics of the text: {}\".format(senReleasesTraining['name'][0]))\n",
    "print(\"are: {}\".format(sen1lda))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now see which topics our model predicts press releases load on and make this into a `dataFrame` for later analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaDF = pandas.DataFrame({\n",
    "        'name' : senReleasesTraining['name'],\n",
    "        'topics' : [senlda[dictionary.doc2bow(l)] for l in senReleasesTraining['reduced_tokens']]\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a bit unwieldy so lets make each topic its own column:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Dict to temporally hold the probabilities\n",
    "topicsProbDict = {i : [0] * len(ldaDF) for i in range(senlda.num_topics)}\n",
    "\n",
    "#Load them into the dict\n",
    "for index, topicTuples in enumerate(ldaDF['topics']):\n",
    "    for topicNum, prob in topicTuples:\n",
    "        topicsProbDict[topicNum][index] = prob\n",
    "\n",
    "#Update the DataFrame\n",
    "for topicNum in range(senlda.num_topics):\n",
    "    ldaDF['topic_{}'.format(topicNum)] = topicsProbDict[topicNum]\n",
    "\n",
    "ldaDF[1::100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's visualize this for several (e.g., 10) documents in the corpus. First we'll subset the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaDFV = ldaDF[:10][['topic_%d' %x for x in range(10)]]\n",
    "ldaDFVisN = ldaDF[:10][['name']]\n",
    "ldaDFVis = ldaDFV.as_matrix(columns=None)\n",
    "ldaDFVisNames = ldaDFVisN.as_matrix(columns=None)\n",
    "ldaDFV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we can visualize as a stacked bar chart:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 10\n",
    "ind = np.arange(N)\n",
    "K = senlda.num_topics  # N documents, K topics\n",
    "ind = np.arange(N)  # the x-axis locations for the novels\n",
    "width = 0.5  # the width of the bars\n",
    "plots = []\n",
    "height_cumulative = np.zeros(N)\n",
    "\n",
    "for k in range(K):\n",
    "    color = plt.cm.coolwarm(k/K, 1)\n",
    "    if k == 0:\n",
    "        p = plt.bar(ind, ldaDFVis[:, k], width, color=color)\n",
    "    else:\n",
    "        p = plt.bar(ind, ldaDFVis[:, k], width, bottom=height_cumulative, color=color)\n",
    "    height_cumulative += ldaDFVis[:, k]\n",
    "    plots.append(p)\n",
    "    \n",
    "\n",
    "plt.ylim((0, 1))  # proportions sum to 1, so the height of the stacked bars is 1\n",
    "plt.ylabel('Topics')\n",
    "\n",
    "plt.title('Topics in Press Releases')\n",
    "plt.xticks(ind+width/2, ldaDFVisNames, rotation='vertical')\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 10))\n",
    "topic_labels = ['Topic #{}'.format(k) for k in range(K)]\n",
    "plt.legend([p[0] for p in plots], topic_labels, loc='center left', frameon=True,  bbox_to_anchor = (1, .5))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also visualize as a heat map:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.pcolor(ldaDFVis, norm=None, cmap='Blues')\n",
    "plt.yticks(np.arange(ldaDFVis.shape[0])+0.5, ldaDFVisNames);\n",
    "plt.xticks(np.arange(ldaDFVis.shape[1])+0.5, topic_labels);\n",
    "\n",
    "# flip the y-axis so the texts are in the order we anticipate (Austen first, then Brontë)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# add a legend\n",
    "plt.colorbar(cmap='Blues')\n",
    "plt.tight_layout()  # fixes margins\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also look at the top words from each topic to get a sense of the semantic (or syntactic) domain they represent. To look at the terms with the highest LDA weight in topic `1` we can do the following:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "senlda.show_topic(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And if we want to make a dataFrame:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topicsDict = {}\n",
    "for topicNum in range(senlda.num_topics):\n",
    "    topicWords = [w for w, p in senlda.show_topic(topicNum)]\n",
    "    topicsDict['Topic_{}'.format(topicNum)] = topicWords\n",
    "\n",
    "wordRanksDF = pandas.DataFrame(topicsDict)\n",
    "wordRanksDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that several of the topics have the same top words, but there are definitely differences. We can try and make the topics more distinct by changing the $\\alpha$ and $\\eta$ parameters of the model. $\\alpha$ controls the sparsity of document-topic loadings, and $\\eta$ controls the sparsity of topic-word loadings.\n",
    "\n",
    "We can make a visualization of the distribution of words over any single topic."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic1_df = pandas.DataFrame(senlda.show_topic(1, topn=50))\n",
    "plt.figure()\n",
    "topic1_df.plot.bar(legend = False)\n",
    "plt.title('Probability Distribution of Words, Topic 1')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See how different $\\eta$ values can change the shape of the distribution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "senlda1 = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, eta = 0.00001)\n",
    "senlda2 = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, eta = 0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic11_df = pandas.DataFrame(senlda1.show_topic(1, topn=50))\n",
    "topic21_df = pandas.DataFrame(senlda2.show_topic(1, topn=50))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7)\n",
    "topic11_df.plot.bar(legend = False, ax = ax1, title = '$\\eta$  = 0.00001')\n",
    "topic21_df.plot.bar(legend = False, ax = ax2, title = '$\\eta$  = 0.9')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that topic model documents related to your anticipated final project. Interrogate and visually plot (e.g., as a bar graph?) the topic-word loadings and the document-topic loadings. What does this topic structure reveal about the distribution of contents across your documents? Systematically vary the $\\alpha$, $\\eta$, and topic number of the model for your text and describe in detail whether and how these changes led to distinctive outcomes, visible to you as analyst.  \n",
    "\n",
    "<span style=\"color:red\">**Stretch**: Cluster your documents, but instead of using words alone, use their topic loadings as an additional set of features. Do these topic loadings increase the apparent semantic coherence of your clusters?</span> "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gensim\n",
    "\n",
    "To do topic modeling we will also be using data from the [grimmer press releases corpus](ttps://github.com/lintool/GrimmerSenatePressReleases). To use the texts with gensim we need to create a `corpua` object, this takes a few steps. First we create a `Dictionary` that maps tokens to ids."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Apply our functions\n",
    "pDF['tokenized_text'] = pDF['text'].apply(lambda x: lucem_illud_2020.word_tokenize(x))\n",
    "pDF['normalized_tokens'] = pDF['tokenized_text'].apply(lambda x: lucem_illud_2020.normalizeTokens(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pDF[::100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dropMissing(wordLst, vocab):\n",
    "    return [w for w in wordLst if w in vocab]\n",
    "\n",
    "pDF['reduced_tokens'] = pDF['normalized_tokens'].apply(lambda x: dropMissing(x, pTFVectorizer.vocabulary_.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(pDF['reduced_tokens'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then for each of the texts we create a list of tuples containing each token and its count. We will only use the first half of our dataset for now and will save the remainder for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in pDF['reduced_tokens']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we serialize the corpus as a file and load it. This is an important step when the corpus is large."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('p.mm', corpus)\n",
    "pmm = gensim.corpora.MmCorpus('p.mm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a correctly formatted corpus that we can use for topic modeling and induction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plda = gensim.models.ldamodel.LdaModel(corpus=pmm, id2word=dictionary, num_topics=10, alpha='auto', eta='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can inspect the degree to which distinct texts load on different topics. Here is one of the texts from the training set:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p1Bow = dictionary.doc2bow(pDF['reduced_tokens'][0])\n",
    "p1lda = plda[p1Bow]\n",
    "print(\"The topics of the text: {}\".format(pDF['intuitive'][0]))\n",
    "print(\"are: {}\".format(p1lda))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now see which topics our model predicts press releases load on and make this into a `dataFrame` for later analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaDF = pandas.DataFrame({\n",
    "        'intuitive' : pDF['intuitive'],\n",
    "        'topics' : [plda[dictionary.doc2bow(l)] for l in pDF['reduced_tokens']]\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a bit unwieldy so lets make each topic its own column:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Dict to temporally hold the probabilities\n",
    "topicsProbDict = {i : [0] * len(ldaDF) for i in range(plda.num_topics)}\n",
    "\n",
    "#Load them into the dict\n",
    "for index, topicTuples in enumerate(ldaDF['topics']):\n",
    "    for topicNum, prob in topicTuples:\n",
    "        topicsProbDict[topicNum][index] = prob\n",
    "\n",
    "#Update the DataFrame\n",
    "for topicNum in range(plda.num_topics):\n",
    "    ldaDF['topic_{}'.format(topicNum)] = topicsProbDict[topicNum]\n",
    "\n",
    "ldaDF[1::100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's visualize this for several (e.g., 10) documents in the corpus. First we'll subset the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaDFV = ldaDF[:10][['topic_%d' %x for x in range(10)]]\n",
    "ldaDFVisN = ldaDF[:10][['intuitive']]\n",
    "ldaDFV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaDFVis = ldaDFV.to_numpy()\n",
    "ldaDFVisNames = ldaDFVisN.to_numpy()\n",
    "ldaDFV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we can visualize as a stacked bar chart:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 10\n",
    "ind = np.arange(N)\n",
    "K = plda.num_topics  # N documents, K topics\n",
    "ind = np.arange(N)  # the x-axis locations for the novels\n",
    "width = 0.5  # the width of the bars\n",
    "plots = []\n",
    "height_cumulative = np.zeros(N)\n",
    "\n",
    "for k in range(K):\n",
    "    color = plt.cm.coolwarm(k/K, 1)\n",
    "    if k == 0:\n",
    "        p = plt.bar(ind, ldaDFVis[:, k], width, color=color)\n",
    "    else:\n",
    "        p = plt.bar(ind, ldaDFVis[:, k], width, bottom=height_cumulative, color=color)\n",
    "    height_cumulative += ldaDFVis[:, k]\n",
    "    plots.append(p)\n",
    "\n",
    "\n",
    "plt.ylim((0, 1))  # proportions sum to 1, so the height of the stacked bars is 1\n",
    "plt.ylabel('Topics')\n",
    "\n",
    "plt.title('Topics in Press Releases')\n",
    "plt.xticks(ind+width/2, ldaDFVisNames, rotation='vertical')\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 10))\n",
    "topic_labels = ['Topic #{}'.format(k) for k in range(K)]\n",
    "plt.legend([p[0] for p in plots], topic_labels, loc='center left', frameon=True,  bbox_to_anchor = (1, .5))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also visualize as a heat map:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.pcolor(ldaDFVis, norm=None, cmap='Blues')\n",
    "plt.yticks(np.arange(ldaDFVis.shape[0])+0.5, ldaDFVisNames);\n",
    "plt.xticks(np.arange(ldaDFVis.shape[1])+0.5, topic_labels);\n",
    "\n",
    "# flip the y-axis so the texts are in the order we anticipate (Austen first, then Brontë)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# add a legend\n",
    "plt.colorbar(cmap='Blues')\n",
    "plt.tight_layout()  # fixes margins\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also look at the top words from each topic to get a sense of the semantic (or syntactic) domain they represent. To look at the terms with the highest LDA weight in topic `1` we can do the following:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "senlda.show_topic(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And if we want to make a dataFrame:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topicsDict = {}\n",
    "for topicNum in range(plda.num_topics):\n",
    "    topicWords = [w for w, p in plda.show_topic(topicNum)]\n",
    "    topicsDict['Topic_{}'.format(topicNum)] = topicWords\n",
    "\n",
    "wordRanksDF = pandas.DataFrame(topicsDict)\n",
    "wordRanksDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that several of the topics have the same top words, but there are definitely differences. We can try and make the topics more distinct by changing the $\\alpha$ and $\\eta$ parameters of the model. $\\alpha$ controls the sparsity of document-topic loadings, and $\\eta$ controls the sparsity of topic-word loadings.\n",
    "\n",
    "We can make a visualization of the distribution of words over any single topic."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic1_df = pandas.DataFrame(plda.show_topic(1, topn=50))\n",
    "plt.figure()\n",
    "topic1_df.plot.bar(legend = False)\n",
    "plt.title('Probability Distribution of Words, Topic 1')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See how different $\\eta$ values can change the shape of the distribution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plda1 = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, eta = 0.00001)\n",
    "plda2 = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, eta = 0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic11_df = pandas.DataFrame(plda1.show_topic(1, topn=50))\n",
    "topic21_df = pandas.DataFrame(plda2.show_topic(1, topn=50))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7)\n",
    "topic11_df.plot.bar(legend = False, ax = ax1, title = '$\\eta$  = 0.00001')\n",
    "topic21_df.plot.bar(legend = False, ax = ax2, title = '$\\eta$  = 0.9')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extending Topic Models within broader research pipelines\n",
    "\n",
    "Topic models can be the base of more complex analysis. One good example is the paper - Individuals, institutions, and innovation in the debates of the French Revolution (https://www.pnas.org/content/115/18/4607), where they use topic models to find similarities and differences between the topics of different individuals. Let us revisit this idea using the Soap opera database. Who innovates and influences the most within the Soap?\n",
    "\n",
    "The next few lines of code follows the same process as last weeks notebook. Please visit the old notebook to read descriptions of the code if you have forgotten what it does."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpora_address = \"/Users/bhargavvader/Downloads/Academics_Tech/corpora/SOAP\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_texts = lucem_illud_2020.loadDavies(corpora_address, num_files=2000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zfile = zipfile.ZipFile(corpora_address + \"/soap_sources.zip\")\n",
    "source = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file in zfile.namelist():\n",
    "    with zfile.open(file) as f:\n",
    "        for line in f:\n",
    "            source.append(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for soap in source[3:]:\n",
    "    try:\n",
    "        textID, year, show, url = soap.decode(\"utf-8\").split(\"\\t\")\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "    if show.strip() not in soap_dict:\n",
    "        soap_dict[show.strip()] = []\n",
    "    if show.strip() in soap_dict:\n",
    "        try:\n",
    "            soap_dict[show.strip()].append(soap_texts[textID.strip()])\n",
    "        except KeyError:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_df = pd.DataFrame(columns=[\"Soap Name\", \"Tokenized Texts\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for soap in soap_dict:\n",
    "    # since there were multiple lists\n",
    "    print(soap)\n",
    "    full_script = []\n",
    "    for part in soap_dict[soap]:\n",
    "        full_script = full_script + part\n",
    "    soap_df.loc[i] = [soap, full_script]\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking to see which index I should use. In my example it is the last one, so I choose my index as 9. It might be different for you!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dool = soap_df['Tokenized Texts'][9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "' '.join(dool[0:1500])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "characters = {}\n",
    "for token in dool:\n",
    "    if token[0] == '@':\n",
    "        # all characters or actions start with @, so we add that to character\n",
    "        if token[2:] not in characters:\n",
    "            characters[token[2:]] = 0\n",
    "        if token[2:] in characters:\n",
    "            characters[token[2:]] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import networkx as nx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actor_network = nx.Graph()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for character in characters:\n",
    "    if characters[character] > 2000:\n",
    "        actor_network.add_node(character, lines_spoken= characters[character], words=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_texts = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for token in dool:\n",
    "    i += 1\n",
    "    if i > len(dool):\n",
    "        break\n",
    "    if token[0] == \"@\":\n",
    "        if token[2:] in actor_network.nodes():\n",
    "            j = i\n",
    "            for token_ in dool[i:]:\n",
    "                if token_[0] == \"@\":\n",
    "                    # if both the characters exist in the graph, add a weight\n",
    "                    if token_[2:] != token[2:] and token_[2:] in actor_network.nodes():\n",
    "                        if (token[2:], token_[2:]) not in actor_network.edges():\n",
    "                            actor_network.add_edge(token[2:], token_[2:], weight=0)\n",
    "                        if (token[2:], token_[2:]) in actor_network.edges():\n",
    "                            actor_network.edges[(token[2:], token_[2:])]['weight'] += 1\n",
    "                    break\n",
    "                j += 1\n",
    "            # adding characters sentences\n",
    "            actor_network.nodes[token[2:]]['words'].append(dool[i:j])\n",
    "            all_texts.append(lucem_illud_2020.normalizeTokens(dool[i:j]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx.draw(actor_network, with_labels=True, font_weight='bold')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok - so we have our graph now. Let us create a topic model with all the texts spoken by the characters, see what's being spoken about, and construct topic distributions for each character. What does our all_texts corpus look like?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_texts[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(all_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in all_texts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('dool.mm', corpus)\n",
    "doolcorpus = gensim.corpora.MmCorpus('dool.mm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doollda = gensim.models.ldamodel.LdaModel(corpus=doolcorpus, id2word=dictionary, num_topics=10, alpha='auto', eta='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doollda.show_topics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Are your topics interpretable/interesting? Sometimes they require a good deal of fine tuning and parameter choosing to get it to work in a nice way. Check out the gensim ldamodel documentation page and see what parameters you can play around with and try the model again!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for actor in actor_network.nodes():\n",
    "    actor_all_words = []\n",
    "    for sent in actor_network.nodes[actor]['words']:\n",
    "        for word in sent:\n",
    "            actor_all_words += word\n",
    "    actor_network.nodes[actor]['topic_distribution'] = doollda[dictionary.doc2bow(lucem_illud_2020.normalizeTokens(actor_all_words))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have topic distributions for each character. Let us have a brief look at what the characters are talking about. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for actor in actor_network.nodes():\n",
    "    print(actor, actor_network.nodes[actor]['topic_distribution'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quickly eye-balling these distributions suggest that the model itself could be tuned better - all the topics are loaded more or less equally. \n",
    "\n",
    "In the paper I linked to earlier, they found similarities or differences using the KL divergence - this is a topic we've dealt with before. Let us plot a heatmap with these values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.matutils import kullback_leibler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_to_prob(bow):\n",
    "    ps = []\n",
    "    for topic_no, topic_prob in bow:\n",
    "        ps.append(topic_prob)\n",
    "    return ps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "L = []\n",
    "for actor_1 in actor_network.nodes():\n",
    "    p = actor_network.nodes[actor_1]['topic_distribution'] \n",
    "    p = convert_to_prob(p)\n",
    "    l = []\n",
    "    for actor_2 in actor_network.nodes():\n",
    "        q = actor_network.nodes[actor_2]['topic_distribution'] \n",
    "        q = convert_to_prob(q)\n",
    "        l.append(kullback_leibler(p, q))\n",
    "    L.append(l)\n",
    "M = np.array(L)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "div = pandas.DataFrame(M, columns = list(actor_network.nodes()), index = list(actor_network.nodes()))\n",
    "ax = sns.heatmap(div)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is one example of how we can use topic models to analyse a network - what other data exploration can you come up with?  Maybe see what are the themes surrounding the top topics for each of the actors? You now have the infrastructure to explore the network and the topics. Gensim has a great set of Jupyter Notebooks which illustrate their methods and functions - https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks. The Auto Examples page also has a good variety of examples - https://radimrehurek.com/gensim/auto_examples/. \n",
    "\n",
    "\n",
    "### Dynamic Topic Modelling\n",
    "\n",
    "Dynamic Topic Modelling is a time based topic model method introduced by David Blei and John Lafferty. It allows one to see topics evolve over a time annotated corpus. I would recommend first viewing the Dynamic Topic Model tutorial on Gensim (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/ldaseqmodel.ipynb) to understand what exactly it's about. \n",
    "\n",
    "(An acknowledgement - Bhargav wrote the code for Gensim's Dynamic Topic Models back in 2016 as a Google Summer of Code student, and they're still using it as are thousands of others!)\n",
    "\n",
    "To demonstrate it on a time based corpus, we will create a corpus from COHA."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpora_address = \"/Users/bhargavvader/Downloads/Academics_Tech/corpora/COHA\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coha_texts = lucem_illud_2020.loadDavies(corpora_address, return_raw=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(coha_texts.keys())[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'd have to approach this differently: note that while extracting the corpus we returned the raw texts (a new functionality in lucem_illud_2020), and the dictionary keys already contain some useful information: the year published, and the genre. neat! We can now create some corpora, organised by year and by genre."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coha_genres = {}\n",
    "coha_years = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for article in coha_texts:\n",
    "    genre, year, id_ = article.split(\"_\")\n",
    "    if genre not in coha_genres:\n",
    "        coha_genres[genre] = []\n",
    "    if genre in coha_genres:\n",
    "        coha_genres[genre].append(coha_texts[article])\n",
    "    \n",
    "    if year not in coha_years:\n",
    "        coha_years[year] = []\n",
    "    if year in coha_years:\n",
    "        coha_years[year].append(coha_texts[article])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coha_genres.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coha_years.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's neat: we have 4 genres and 200 years. We have to now decide how many time slices we want. Let us see how the corpus is distributed.\n",
    "\n",
    "If you went through the tutorial, you would notice how we would need to arrange the corpora year wise.\n",
    "We also have to arrange the number of topics per year."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import collections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years = []\n",
    "year_lens = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for year_info in collections.OrderedDict(sorted(coha_years.items())):\n",
    "    years.append(year_info)\n",
    "    year_lens.append(len((coha_years[year_info])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years[0], years[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(years, year_lens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The X axis isn't legible, but you can get the point: there are far less articles in the beginning, and then it grows. Maybe in our 5 time slices, we do: 1810-1880, 1881-1913, 1914-1950, 1950-1990, 1990-2009?\n",
    "I use some historical intuition to use these time periods, you are encouraged to try your different time slices (for e.g, 20 10 year periods, 10 20 year periods, by total number of papers, etc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_texts_coha = []\n",
    "docs_per_timeslice = [0, 0, 0, 0, 0]\n",
    "i = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for year_info in collections.OrderedDict(sorted(coha_years.items())):\n",
    "    large_files = 0\n",
    "    for article in coha_years[year_info]:\n",
    "        try:\n",
    "            if len(article[2]) < 1500000:\n",
    "                all_texts_coha.append(lucem_illud_2020.normalizeTokens(article[2].decode(\"utf-8\")))\n",
    "            if len(article[2]) >= 1500000:\n",
    "                large_files += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "    # these numbers are the number of years in the \n",
    "    if i < 70:\n",
    "        docs_per_year[0] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 70 and i < 103:\n",
    "        docs_per_year[1] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 103 and i < 140:\n",
    "        docs_per_year[2] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 140 and i < 180:\n",
    "        docs_per_year[3] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 180:\n",
    "        docs_per_year[4] += len(coha_years[year_info]) - large_files\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Smaller Corpora\n",
    "\n",
    "The original size of the corpus is wayyy too big for our laptops. Let us demo this with a smaller size. You are welcome to try different sizes until you get the size you would like.\n",
    "I am using a 100 documents per time slice for this example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def choose_n(corpus, time_slices, nums=100):\n",
    "    new_corpus = corpus[0:nums]\n",
    "    for time_slice in time_slices[:-1]:\n",
    "        new_corpus = new_corpus + corpus[time_slice:time_slice+nums]\n",
    "    return new_corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, COHA also has some really large files, full books and the like: we're going to now split up really large files such that each of the documents are only 1000 tokens long. This function will return a split up document and the number of files it has been split into, so we can accordingly adjust the documents per time slice, which is important for Dynamic Topic Modelling to work."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_up(document, doc_size=1000):\n",
    "    new_docs = [document[i:i + doc_size] for i in range(0, len(document), doc_size)]\n",
    "    return(new_docs, len(new_docs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "small_corpus = choose_n(all_texts_coha, docs_per_year, nums=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_corpus= []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_per_time_slice = [0, 0, 0, 0, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I now use the split method to create my final corpus. Note that I hardcode values for the time slice to figure out the number of documets per time slice. Now I have a representative number of documents in each time slice. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, article in enumerate(small_corpus):\n",
    "    # identify time slice based on article number \n",
    "    if i < 100:\n",
    "        time = 0\n",
    "    if i > 100 and i <= 200:\n",
    "        time = 1\n",
    "    if i > 200 and i <= 300:\n",
    "        time = 2\n",
    "    if i > 300 and i <= 400:\n",
    "        time = 3\n",
    "    if i > 400 and i <= 500:\n",
    "        time = 4\n",
    "        \n",
    "    if len(article) > 1000:\n",
    "        split_docs, no_docs = split_up(article)\n",
    "        for doc in split_docs:\n",
    "            final_corpus.append(doc)\n",
    "        docs_per_time_slice[time] += no_docs\n",
    "    else:\n",
    "        final_corpus.append(article)\n",
    "        docs_per_time_slice[time] += 1\n",
    "    # just a check if the counts are correctly added\n",
    "    if np.sum(docs_per_time_slice) != len(final_corpus):\n",
    "        print(np.sum(docs_per_time_slice), len(final_corpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(final_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in final_corpus]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('coha.mm', corpus)\n",
    "cohacorpus = gensim.corpora.MmCorpus('coha.mm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import ldaseqmodel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=docs_per_time_slice, num_topics=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaseq.print_topics(time=0)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " ldaseq.print_topics(time=4)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What can you see from the analysis? I encourage you to explore the tutorial and see what else you can do with this dataset. In the above model I can see how the topic related to state evolves slowly, with the word president not previously there coming into the topic. I will now save this model and also upload it on GitHub so that you can see how it works. Note that the Dynamic Topic Model is a very time consuming algorithm: you might want to start a run overnight if you intend on using it in your analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ldaseq.save(\"ldaseqmodel\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = ldaseqmodel.LdaSeqModel.load(\"ldaseqmodel\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that use topic models and networks, or dynamic topic models on datasets relevant to your final project. You can also extend the analysis of the COHA or Soap datasets, if relevant to the comparison of data for your projects. (You could possibly use coha_genres dictionary to conduct analysis on topic evolution for a particular genre? What themes do you see evolving throughout these corpora?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extending Topic Models within broader research pipelines\n",
    "\n",
    "Topic models can be the base of more complex analysis. One good example is the paper - Individuals, institutions, and innovation in the debates of the French Revolution (https://www.pnas.org/content/115/18/4607), where they use topic models to find similarities and differences between the topics of different individuals. Let us revisit this idea using the Soap opera database. Who innovates and influences the most within the Soap?\n",
    "\n",
    "The next few lines of code follows the same process as last weeks notebook. Please visit the old notebook to read descriptions of the code if you have forgotten what it does."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpora_address = \"/Users/bhargavvader/Downloads/Academics_Tech/corpora/SOAP\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_texts = lucem_illud_2020.loadDavies(corpora_address, num_files=2000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zfile = zipfile.ZipFile(corpora_address + \"/soap_sources.zip\")\n",
    "source = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file in zfile.namelist():\n",
    "    with zfile.open(file) as f:\n",
    "        for line in f:\n",
    "            source.append(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for soap in source[3:]:\n",
    "    try:\n",
    "        textID, year, show, url = soap.decode(\"utf-8\").split(\"\\t\")\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "    if show.strip() not in soap_dict:\n",
    "        soap_dict[show.strip()] = []\n",
    "    if show.strip() in soap_dict:\n",
    "        try:\n",
    "            soap_dict[show.strip()].append(soap_texts[textID.strip()])\n",
    "        except KeyError:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_df = pd.DataFrame(columns=[\"Soap Name\", \"Tokenized Texts\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for soap in soap_dict:\n",
    "    # since there were multiple lists\n",
    "    print(soap)\n",
    "    full_script = []\n",
    "    for part in soap_dict[soap]:\n",
    "        full_script = full_script + part\n",
    "    soap_df.loc[i] = [soap, full_script]\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soap_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [
    {
     "data": {
      "text/plain": "                liked_by                                               text  \\\n0               21962602  \"“FOLLOWED BY ALL” ACTION STEPS\" #GinoWickman,...   \n1    1046930262268006400  I’ve never been a cat person. We got Luna for ...   \n2               70901647  @manusia_jawa_1 @mahabintangjr @KompasTV https...   \n3               14218396  I miss having dinner parties. I miss going to ...   \n4               14088454  That may put someone over the $500 allowable t...   \n..                   ...                                                ...   \n475           2165526102  @SonicFox Thank you for the promotion@SonicFox...   \n476             25776263  Many have said that what transpired on Wednesd...   \n477             36419649  @rsosa8 Some great books!Best call of the year...   \n478             16494284  @danprimack @axios A good chunk of fintech see...   \n479            838301000  Today is Ted Danson’s birthday.Betsy DeVos has...   \n\n     type  extravert  intuitive  thinking  judging  kmeans_predictions  \\\n0    ISTJ          0          0         1        1                   1   \n1    ISTP          0          0         1        0                   1   \n2    ISTP          0          0         1        0                   0   \n3    ISTJ          0          0         1        1                   1   \n4    ISTJ          0          0         1        1                   0   \n..    ...        ...        ...       ...      ...                 ...   \n475  INFP          0          1         0        0                   1   \n476  ENFP          1          1         0        0                   1   \n477  ENFP          1          1         0        0                   1   \n478  ENTJ          1          1         1        1                   1   \n479  INTP          0          1         1        0                   1   \n\n     wald_predictions                                     tokenized_text  \\\n0                   4  [FOLLOWED, BY, ALL, ACTION, STEPS, GinoWickman...   \n1                   3  [I, ’ve, never, been, a, cat, person, We, got,...   \n2                   1  [@manusia_jawa_1, @mahabintangjr, @KompasTV, h...   \n3                   4  [I, miss, having, dinner, parties, I, miss, go...   \n4                   2  [That, may, put, someone, over, the, $, 500, a...   \n..                ...                                                ...   \n475                 4  [@SonicFox, Thank, you, for, the, promotion@So...   \n476                 3  [Many, have, said, that, what, transpired, on,...   \n477                 4  [@rsosa8, Some, great, books!Best, call, of, t...   \n478                 4  [@danprimack, @axios, A, good, chunk, of, fint...   \n479                 3  [Today, is, Ted, Danson, ’s, birthday, Betsy, ...   \n\n                                     normalized_tokens  \\\n0    [follow, action, step, ginowickman, traction, ...   \n1    [have, cat, person, get, luna, kid, pick, huma...   \n2    [@manusia_jawa_1, @mahabintangjr, @kompastv, h...   \n3    [miss, have, dinner, party, miss, go, movie, b...   \n4    [$, allowable, tax, deduction, educator, https...   \n..                                                 ...   \n475  [@sonicfox, thank, promotion@sonicfox, @dooble...   \n476  [say, transpire, wednesday, america, wrong, am...   \n477  [@rsosa8, great, books!best, year, right, http...   \n478  [@danprimack, @axios, good, chunk, fintech, tr...   \n479  [today, ted, danson, birthday, betsy, devos, j...   \n\n                                        reduced_tokens  \n0    [action, step, leadership, phone, pm, monday, ...  \n1    [cat, kid, pick, dog, sit, weird, wonder, ban,...  \n2    [lie, orang, tapi, kita, di, ini, ada, yang, o...  \n3    [dinner, movie, bar, travel, conference, event...  \n4    [tax, teacher, create, experience, student, bu...  \n..                                                 ...  \n475  [powerful, holy, hello, player, youtube, updat...  \n476  [wednesday, late, experience, member, congress...  \n477  [fan, join, near, conference, situation, agree...  \n478  [model, realize, terrible, dog, business, rais...  \n479  [ted, student, surprise, amendment, education,...  \n\n[480 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>liked_by</th>\n      <th>text</th>\n      <th>type</th>\n      <th>extravert</th>\n      <th>intuitive</th>\n      <th>thinking</th>\n      <th>judging</th>\n      <th>kmeans_predictions</th>\n      <th>wald_predictions</th>\n      <th>tokenized_text</th>\n      <th>normalized_tokens</th>\n      <th>reduced_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21962602</td>\n      <td>\"“FOLLOWED BY ALL” ACTION STEPS\" #GinoWickman,...</td>\n      <td>ISTJ</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>[FOLLOWED, BY, ALL, ACTION, STEPS, GinoWickman...</td>\n      <td>[follow, action, step, ginowickman, traction, ...</td>\n      <td>[action, step, leadership, phone, pm, monday, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1046930262268006400</td>\n      <td>I’ve never been a cat person. We got Luna for ...</td>\n      <td>ISTP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>[I, ’ve, never, been, a, cat, person, We, got,...</td>\n      <td>[have, cat, person, get, luna, kid, pick, huma...</td>\n      <td>[cat, kid, pick, dog, sit, weird, wonder, ban,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70901647</td>\n      <td>@manusia_jawa_1 @mahabintangjr @KompasTV https...</td>\n      <td>ISTP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[@manusia_jawa_1, @mahabintangjr, @KompasTV, h...</td>\n      <td>[@manusia_jawa_1, @mahabintangjr, @kompastv, h...</td>\n      <td>[lie, orang, tapi, kita, di, ini, ada, yang, o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14218396</td>\n      <td>I miss having dinner parties. I miss going to ...</td>\n      <td>ISTJ</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>[I, miss, having, dinner, parties, I, miss, go...</td>\n      <td>[miss, have, dinner, party, miss, go, movie, b...</td>\n      <td>[dinner, movie, bar, travel, conference, event...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14088454</td>\n      <td>That may put someone over the $500 allowable t...</td>\n      <td>ISTJ</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[That, may, put, someone, over, the, $, 500, a...</td>\n      <td>[$, allowable, tax, deduction, educator, https...</td>\n      <td>[tax, teacher, create, experience, student, bu...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>2165526102</td>\n      <td>@SonicFox Thank you for the promotion@SonicFox...</td>\n      <td>INFP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>[@SonicFox, Thank, you, for, the, promotion@So...</td>\n      <td>[@sonicfox, thank, promotion@sonicfox, @dooble...</td>\n      <td>[powerful, holy, hello, player, youtube, updat...</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>25776263</td>\n      <td>Many have said that what transpired on Wednesd...</td>\n      <td>ENFP</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>[Many, have, said, that, what, transpired, on,...</td>\n      <td>[say, transpire, wednesday, america, wrong, am...</td>\n      <td>[wednesday, late, experience, member, congress...</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>36419649</td>\n      <td>@rsosa8 Some great books!Best call of the year...</td>\n      <td>ENFP</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>[@rsosa8, Some, great, books!Best, call, of, t...</td>\n      <td>[@rsosa8, great, books!best, year, right, http...</td>\n      <td>[fan, join, near, conference, situation, agree...</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>16494284</td>\n      <td>@danprimack @axios A good chunk of fintech see...</td>\n      <td>ENTJ</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>[@danprimack, @axios, A, good, chunk, of, fint...</td>\n      <td>[@danprimack, @axios, good, chunk, fintech, tr...</td>\n      <td>[model, realize, terrible, dog, business, rais...</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>838301000</td>\n      <td>Today is Ted Danson’s birthday.Betsy DeVos has...</td>\n      <td>INTP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>[Today, is, Ted, Danson, ’s, birthday, Betsy, ...</td>\n      <td>[today, ted, danson, birthday, betsy, devos, j...</td>\n      <td>[ted, student, surprise, amendment, education,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>480 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking to see which index I should use. In my example it is the last one, so I choose my index as 9. It might be different for you!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "outputs": [],
   "source": [
    "person = pDF['tokenized_text'].sample(n = 50).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "outputs": [
    {
     "data": {
      "text/plain": "'ty for the follows Prunuss and Phoebe lt;3 expect more streams this month and next 333A sad tale https://t.co/9cXdYRnDcgEVO Moment 98 https://t.co/3IhviIrQXmam I a shiny hunter now ENG GER https://t.co/v15VLBDKvXVolleyball gt wolf@ZainNaghmi ill see you soon sir@TSM_Leffen ok \"Marth Wolf is 90 10 all Marth players are trash how come they get hit by his side b finishes he has no real kill options how do you manage to drop that chain grab are we even playing the same game https://t.co/iiOnTj786h https://t.co/8c7f2BN2DXMietvertrag ist unterschrieben abgeschickt Jetzt ist es offiziell!VOLLEYBOND incoming once i m better https://t.co/FrP9IOETpdI fucking love melee community this is so hype LOL https://t.co/Ym6kEMqfHtThat \\'s not all Wolf is now in development as a playable character in The Akaneia Build You can try him out in your experimental build Download here https://t.co/CsS7zkjrzx https://t.co/AGZkyomfPEIntroducing a brand new mode play Volleyball in The Akaneia Build and smash the ball over the net https://t.co/46LZrVOHwWWhen the plan works out https://t.co/lm9DxIyvB2 https://t.co/DzOB0ZPOEaSmall update in preparation for a larger beta One major change though Unranked MMR and SBMM for lower level players More details in thread https://t.co/8xI8OuU56uToday my puff pushes its limits https://t.co/tQ1e8NR4MD https://t.co/0m0ZSMMVp3If a 5 0 is a myb what \\'s a 7 0 in sets https://t.co/prToWoKgL5 https://t.co/JM2QMT2cAiI met Hbox at the grocery store He said pal I \\'ve been looking for 9 hours and ca n\\'t find a single grocery in this shithole I said are you doing okay Hbox He looked up at me and said buddy this conversation is clutch as fuck and I \\'m barely even trying \"did a pov style render of @SsbmGinger \\'s dsmash to beat hbox at Smash summit 10 https://t.co/Jsv0JHQla3I miss the old pokemon anime https://t.co/bPz5KHdTdf@konaklaert @MythosOfGaming Man munkelt das Spiel wäre sogar ziemlich gut kostenlos und könnte noch ein paar Runner gebrauchen lt;3Stream starting now =D https://t.co/hCges5hHySNew video up I spend too much money on Pokémon cards again and Floki needed attention right when I streamed https://t.co/zLCxrX609F Genshin https://t.co/L62NZyOPvIHeute ist Donald Trumps letzter Tag als US Präsident Um die Räumung des Weißen Hauses zu verhindern hat er sich an einem Ort versteckt an dem ihn niemand vermutet in seinem Arbeitszimmer TrumpI binged read the AoT manga in the last two days from where the anime is and it \\'s incredibleEN I finally found a not too expensive offer for the only true special edition the WiiU ever got Also it \\'s in a good condition definitely better than my current Wii U even though gloss black always comes with some micro scratches I \\'m just super happyEndlich habe ich ein gutes Angebot für die einzig wirkliche Special Edition die die WiiU jemals hatte gefunden Zustand ist auch ziemlich gut definitiv besser als meine derzeitige Wii U auch wenn schwarz glanz immer mit ein paar Mikrokratzern daherkommt Bin mega happy https://t.co/6WzsIy0UqvGood morning here ’s a pic of me and my bestie 2 years ago https://t.co/2dIGWL6KFpHaven\\'t posted any controllers in a while working through some orders to get ready for my drop late January early February https://t.co/XcHm3U8dOOZusage für die erste Wahl bekommen Nice1.5 million impressions of my disrespect for Nintendo wym https://t.co/GrWrJrvcZzframe 1 progress a week and change in https://t.co/V0EloSRE4vNeues Lets Play Ziel ist ein möglichst mieses Ende Deswegen folgt mir und MaleV beim Arschloch sein Vergesst nicht zu kommentieren(nicht zum gameplay ich versuch damit editing zu lernen amp https://t.co/sfTpNLT4ov https://t.co/WUlhaFCBACThis tweet is the one time you ’re allowed to self promo Reply with whatever!@Kru3on @konaklaert @A_Seagull @ArmadaUGS Würde mich auch interessieren Erstmal noch abwarten ob die erste Wahl etwas wird aber gut zu wissen dass man schon einen Plan B hab!Mir wurde indirekt eine Wohnung zugesagt Coolok NintendoSwitch https://t.co/vVurZBORA2Das ist nicht mal mehr lustig Das ist die Ausbeute von 20 Packs https://t.co/D1ZFXfHIWoIch bin auf der Suche nach Shiny Pokémon Karten https://t.co/c6HAVMSLHS https://t.co/UyRCPCAp3X@SFAT I was making dinner while watching your win plantgang https://t.co/gny09UB8g8Overall I think the tournament ran well and like how they let us play our matches without us waiting then used the Slippi VODS for the stream But I wish Bo5 started sooner like at least Top 12 Good tournament though Thx JasonTook 1st at M2 K \\'s Frame Perfect Series GGs everyone Back to baaaack babyyyy@jProficiency @Victuagarza @ssbmhax That would mean Hax would be the one who is responsible for the lagging genius@ssbmhax Better fox won today 3@ssbmhax https://t.co/zT59H9xwNG@ssbmhax John is that you?@ssbmhax https://t.co/cJ3mqakyjb@ssbmhax https://t.co/OTNBj0biufShort practice stream coming up =) https://t.co/hCges5hHySIch werde Karten auspacken https://t.co/c6HAVMSLHS https://t.co/dzyZ9lzCAC1st at the first @RollbackRumble ggs everyone Hab eine fantastische Wohnung besichtigt Jetzt muss ich nur noch die förmlichen Sachen abklären und hoffen dass wir den Mietvertrag unterschrieben dürfen@konaklaert @A_Seagull @ArmadaUGS Huch wo kann man das sehen ° https://t.co/8QqssXDmiR@vibeacevibing @ZainNaghmi thank you for tuning in with us Thank you for keeping me entertained @ZainNaghmi and @BTSsmash https://t.co/vkq5qEjs3jThe joys of being a puppy parent D zombie hilda mode on https://t.co/q60rUSnhRtGute Neuigkeiten Ich habe das GBA Video noch fertig bekommen Heute veröffentliche es noch für Patrons etc und morgen dann für alle Ist ein gutes Video Bin zufrieden.https://t.co/LdbzANizLtLevo is today starting at 7PM Looking real stacked do n\\'t forget to signup https://t.co/lCUyjFOMoVIch bin ein Held https://t.co/rLoFlkvv2pDas größte Problem am haarlosen Mann Dasein ist dass man mindestens 1x pro Woche die traurigen Überreste von Haarwuchs trimmen muss.784 entrants for Frame Perfect Series 4 Yo this is crazy I \\'m so happy at how this is growing I feel really good about the future This is also really fun to do each monthWhen Nintendo finds people playing their old games https://t.co/1nmlje7663ice sea shanty https://t.co/sQUXqbwMIN@itsyourboykrieg @MVG_Mew2King we just get each other i guess On this beautiful ThrowbackThursday We \\'re thinking about how @MVG_Mew2King \\'s first reaction to winning SmashSummit 6 was just pure shock Simply an iconic moment https://t.co/tyWwvpbyTSGanz gleich ob ihr neu i m PvP von Guild Wars 2 oder erfahrene Kämpfer seid der offizielle ArenaNet Partner https://t.co/WeUKkHmvuE hilft euch am Ball zu bleiben https://t.co/c05ZhkENNs https://t.co/8m1D0hwLFsFriedrich Merz nennt die stärkere Besteuerung von höheren Einkommen eine Neidsteuer Klare Worte des Arroganzpolitikers“ Ich bin kein Fan davon wenn man aus welchen Gründen auch immer die Größe eine Fensters in Windows geändert hat und einfach nicht mehr die ursprüngliche Größe findet Es irritiert mich sehr.(2016 @n0ned vs @theprinceofssbm at Sweet XXIV Where I \\'m from we call this the corporate takeover https://t.co/XNfSbtPNcwEven actual foxes are better at dashdancing than me https://t.co/DniOrtzzkHhey guys just letting everyone know my tourney starts TOMORROW 4 day event Thurs Sun If you guys know anybody interested in Melee Ultimate Project Plus Kirby Fighters 2 Rivals of Aether Smash 64 Remix or Smash Flash 2 then please let them know!Ja ich habe es gekauft Auch wenn ich das ganze mit der zeitl Limitierung eigentlich nicht unterstützen möchte und ziemlich bescheiden finde Wenigstens habe ich durchs Warten 15 € i m Vergleich zu den ganzen Pre Order Leuten gespart Oh und Pichu sagt hallo https://t.co/OH4k819IWu#NewProfilePic https://t.co/qhew8Dw70gAnyone who makes GCC L R buttons -&gt Mechanical switches I know there was a thing about it before been wanting to try it out along with a really good trigger plug Ich komme so dermaßen langsam bei meinem nächsten Video voran es ist nicht mal mehr lustig Aber dafür habe ich etwas mit dem Slider experimentiert Sind ein paar nette Aufnahmen geworden https://t.co/LFoivnVy09my grandma says she wants to leave me her jewelry when she dies but I do n’t think i ’m ready for that kind of responsibility so my current game plan is to do everything in my power to die before her Ich erstickt fast an einer Pommes in der Luftröhre Mein Bruder https://t.co/alhfI6fhKEthis made me Laugh Out Loud like if it made you Laugh Out Loud too https://t.co/VACUeRCVSDWohunungssuche sucktMy hair has finally achieved it \\'s truest form The Rachel lt;3 https://t.co/BDpkU3hc9Whttps://t.co/LwlUGWMo7ogotta dress the part for momentous occasions https://t.co/CUadxbS7WaThis may be the There ’s always a tweet to end all There ’s always a tweet”s https://t.co/gX0p5hF1x7We tried 2nd at Galint Melee Open Great adaptions going into grands Shoutout to @BobbySiege for the pre grands pep talk GGs @LiquidHbox you earned it Thanks for a great stream today everyone https://t.co/Bb9YF4HmtM@konaklaert Er lebt https://t.co/ScTGi1PjhdGAME 5 LAST STOCK @n0ned OUTTA NOWHERE WITH THE KNEE READ Whew With that he \\'s moving on in the bracket @C9Mang0 amp @OXY_Crimson https://t.co/XCTlXMrKpy https://t.co/H7eQGnsxnVhttps://t.co/rKKkkAq361 https://t.co/PF9enbW02Z@ZainNaghmi Rest up king Also i m down for fall guys too@konaklaert Ist mal wieder ein wundervolles Video geworden lt;3DQing from Galint Honestly feel pretty lame about it apologies to everyone who wanted to see me play My hand have been hurting bad and I should \\'ve know that I wanted a break from melee before Only thing keeping me getting another shot at Axe in bracket Sorry everyone@konaklaert Dich gibt \\'s noch https://t.co/Mf0wMMho1m@konaklaert Willkommen zurück https://t.co/Tq0CpLN4okNo words can truly express how much I appreciate everything she did to raise me and my brothers I \\'m just happy that she \\'s no longer hurting Love you Mom Rest in peace https://t.co/sb7OHHZvAYLive Talking about why I \\'m switching from the Gamecube controller EU scene stuff and then playing TOs in for SAME https://t.co/8NOSC7r3wT https://t.co/OyyBB51BcJGanyu GenshinImpact https://t.co/F6FhSKPRQuDiese URL wurde extra'"
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(person[0:1500])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "outputs": [],
   "source": [
    "characters = {}\n",
    "for token in person:\n",
    "    if token[0] == '@':\n",
    "        # all characters or actions start with @, so we add that to character\n",
    "        if token[2:] not in characters:\n",
    "            characters[token[2:]] = 0\n",
    "        if token[2:] in characters:\n",
    "            characters[token[2:]] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "outputs": [],
   "source": [
    "import networkx as nx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "outputs": [],
   "source": [
    "person_network = nx.Graph()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "outputs": [],
   "source": [
    "for character in characters:\n",
    "    if characters[character] > 20:\n",
    "        person_network.add_node(character, lines_spoken= characters[character], words=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "outputs": [],
   "source": [
    "i = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "outputs": [],
   "source": [
    "all_texts = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "outputs": [],
   "source": [
    "for token in person:\n",
    "    i += 1\n",
    "    if i > len(person):\n",
    "        break\n",
    "    if token[0] == \"@\":\n",
    "        if token[2:] in person_network.nodes():\n",
    "            j = i\n",
    "            for token_ in person[i:]:\n",
    "                if token_[0] == \"@\":\n",
    "                    # if both the characters exist in the graph, add a weight\n",
    "                    if token_[2:] != token[2:] and token_[2:] in person_network.nodes():\n",
    "                        if (token[2:], token_[2:]) not in person_network.edges():\n",
    "                            person_network.add_edge(token[2:], token_[2:], weight=0)\n",
    "                        if (token[2:], token_[2:]) in person_network.edges():\n",
    "                            person_network.edges[(token[2:], token_[2:])]['weight'] += 1\n",
    "                    break\n",
    "                j += 1\n",
    "            # adding characters sentences\n",
    "            person_network.nodes[token[2:]]['words'].append(person[i:j])\n",
    "            all_texts.append(lucem_illud_2020.normalizeTokens(person[i:j]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(person_network, with_labels=True, font_weight='bold')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok - so we have our graph now. Let us create a topic model with all the texts spoken by the characters, see what's being spoken about, and construct topic distributions for each character. What does our all_texts corpus look like?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [
    {
     "data": {
      "text/plain": "[['assemble',\n  'diverse',\n  'team',\n  'brilliant',\n  'scientist',\n  'elevate',\n  'role',\n  'science',\n  'work',\n  'scienceisback!biden',\n  'rejoin',\n  'paris',\n  'climate',\n  'accord',\n  'executive',\n  'order',\n  'official',\n  'president',\n  'donald',\n  'trump',\n  'long',\n  'immune',\n  'criminal',\n  'prosecution',\n  'prosecutor',\n  'stand',\n  'stand',\n  'wish',\n  'invoice',\n  'people',\n  'waste',\n  'time?never',\n  'forget',\n  'blue',\n  'check',\n  'sacrifice',\n  'https://t.co/4qj8vkjzcdlet',\n  'complete',\n  'quote',\n  'meijer',\n  'say',\n  'nonchalantly',\n  'important',\n  'elect',\n  'leader',\n  'think',\n  'solely',\n  'self',\n  'interest',\n  'politically',\n  'expedient',\n  'actually',\n  'need',\n  'country',\n  'https://t.co/9u4rvtk0ojlisten',\n  'customer',\n  'constantly',\n  'answer',\n  'darling',\n  'notice',\n  'have',\n  'pretend',\n  'multitask',\n  'wonder',\n  'want',\n  'talk',\n  'https://t.co/ptn9oxjkvkelle',\n  'wood',\n  'proud',\n  'https://t.co/v2nichaonjwhen',\n  'kamala',\n  'office',\n  'https://t.co/al2nq8v4lcalready',\n  'home',\n  'ride',\n  'https://t.co/d0bvjiifpbmental',\n  'health',\n  'health',\n  'thing',\n  'yesterday',\n  'learn',\n  'turn',\n  'zoom',\n  'makeup',\n  'today',\n  'find',\n  'bo',\n  'sit',\n  'lap',\n  'zoom',\n  'get',\n  'eyebrow',\n  'lip',\n  'want',\n  'minute',\n  'zoomy',\n  'pick',\n  'lucky',\n  'twitterer!san',\n  'diego',\n  'startups',\n  'tear',\n  'https://t.co/rupnwojroxi',\n  'stand',\n  'shoulder',\n  'come',\n  'https://t.co/jtoj4o7hnmgreta',\n  'give',\n  'hope',\n  'future',\n  'https://t.co/pj7poehcgqthrilled',\n  'share',\n  'join',\n  'biden',\n  'administration',\n  'chief',\n  'staff',\n  'fossil',\n  'energy',\n  'doe',\n  'excite',\n  'join',\n  'amaze',\n  'team',\n  'refocus',\n  'office',\n  'climate',\n  'equity',\n  '+',\n  'expand',\n  'work',\n  'carbon',\n  'removal',\n  'industrial',\n  'decarbonization',\n  'carbontech',\n  'special',\n  'sunrise',\n  'morning',\n  'look',\n  'are?i',\n  'want',\n  'potus',\n  'lol',\n  'https://t.co/osewsch1ysi’ve',\n  'intense',\n  'anxiety',\n  'dream',\n  'lead',\n  'today',\n  'be',\n  'glad',\n  'tonight',\n  'rest',\n  'easy.welp',\n  'https://t.co/i0iqc9hzlymost',\n  'build',\n  'technology',\n  'company',\n  'figure',\n  'scale',\n  'long',\n  'tail',\n  'ceo',\n  'share',\n  'biden',\n  'message',\n  'team',\n  'be',\n  'joke',\n  'work',\n  'hear',\n  'treat',\n  'disrespect',\n  'talk',\n  'fire',\n  'spot',\n  'spot',\n  'ifs',\n  'ands',\n  'but',\n  'people',\n  'way',\n  'catch',\n  'national',\n  'politic',\n  'know',\n  'represent',\n  'locally',\n  'hope',\n  'humanity',\n  'evolve',\n  'past',\n  'unthinking',\n  'tribalism',\n  'lifetime.@tedcruz',\n  'haha',\n  'fuck',\n  'fascist',\n  'encourage',\n  'white',\n  'supremacist',\n  'insurrection',\n  'fuck',\n  'clown.@rsg'],\n ['https://t.co/0lf7ihsgetand',\n  'get',\n  'away',\n  'meddle',\n  'kids.10:30',\n  'drop',\n  'dry',\n  'clean',\n  '11:00',\n  'joe',\n  'thing',\n  '2:00',\n  'swing',\n  'post',\n  'office',\n  'https://t.co/jjr3seckebwinston',\n  'churchill',\n  'grave',\n  'rn',\n  'https://t.co/aizml4o9x5you',\n  'amanda',\n  'gorman',\n  'feel',\n  'art',\n  'matter',\n  'ability',\n  'cut',\n  'get',\n  'right',\n  'heart',\n  'matt',\n  'guarantee',\n  'forget',\n  'majority',\n  'speech',\n  'hard',\n  'forget',\n  'today',\n  'historic',\n  'day',\n  'congratulation',\n  'new',\n  'president'],\n ['new', 'vice', 'president'],\n ['inauguration',\n  'president',\n  'unite',\n  'state',\n  'country',\n  'tackle',\n  'history',\n  'great',\n  'challenge',\n  'be',\n  'look',\n  'forward',\n  'continue',\n  'partnership'],\n ['success',\n  'country',\n  'success',\n  'https://t.co/btvwsgn5ihopposite',\n  'doomscrollingi',\n  'virus',\n  'virus',\n  'get',\n  'hello'],\n [],\n ['wish', 'like', 'tweet', 'see', 'software'],\n ['crow',\n  'build',\n  'impress',\n  'life',\n  'sense',\n  'look',\n  'backwards',\n  'trust',\n  'end',\n  'well',\n  'position',\n  'professionally',\n  'amp',\n  'happy',\n  'end',\n  'day',\n  'embrace',\n  'gap',\n  'money',\n  'online',\n  'explain',\n  'make',\n  'money',\n  'parent'],\n ['feedback',\n  'great',\n  'strategy',\n  'have',\n  'outline',\n  'struggle',\n  'anxiety',\n  'depression',\n  'go',\n  'exercise',\n  'help',\n  'immensely',\n  'job',\n  'control',\n  'spend',\n  'energy',\n  'time',\n  'time',\n  'breathe',\n  'thank',\n  'grab',\n  'guide',\n  'supercharge',\n  'productivity',\n  'break',\n  'neck',\n  'try',\n  'nice'],\n ['https://t.co/lv8fdg82dwintroducing',\n  'instagram',\n  'live',\n  'thank',\n  'encouragement',\n  'crowd']]"
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(all_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in all_texts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('person.mm', corpus)\n",
    "pcorpus = gensim.corpora.MmCorpus('person.mm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "outputs": [],
   "source": [
    "plda = gensim.models.ldamodel.LdaModel(corpus=pcorpus, id2word=dictionary, num_topics=10, alpha='auto', eta='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0,\n  '0.015*\"sorry\" + 0.013*\"be\" + 0.010*\"loss\" + 0.008*\"time\" + 0.007*\"bbb21\" + 0.007*\"love\" + 0.006*\"need\" + 0.005*\"thank\" + 0.004*\"amaze\" + 0.004*\"send\"'),\n (1,\n  '0.009*\"be\" + 0.009*\"amp\" + 0.006*\"thank\" + 0.005*\"get\" + 0.004*\"podcast\" + 0.004*\"new\" + 0.004*\"day\" + 0.004*\"de\" + 0.004*\"courage\" + 0.003*\"dia\"'),\n (2,\n  '0.011*\"be\" + 0.010*\"thank\" + 0.008*\"dia\" + 0.007*\"work\" + 0.007*\"like\" + 0.006*\"need\" + 0.006*\"great\" + 0.005*\"day\" + 0.004*\"time\" + 0.004*\"twice\"'),\n (3,\n  '0.018*\"be\" + 0.013*\"sorry\" + 0.011*\"know\" + 0.008*\"loss\" + 0.008*\"time\" + 0.007*\"family\" + 0.006*\"de\" + 0.006*\"thank\" + 0.005*\"go\" + 0.005*\"dia\"'),\n (4,\n  '0.009*\"well\" + 0.007*\"bbb21\" + 0.007*\"be\" + 0.005*\"o\" + 0.005*\"e\" + 0.005*\"que\" + 0.004*\"love\" + 0.004*\"amp\" + 0.004*\"year\" + 0.004*\"é\"'),\n (5,\n  '0.009*\"new\" + 0.007*\"work\" + 0.006*\"year\" + 0.006*\"amaze\" + 0.005*\"de\" + 0.005*\"amp\" + 0.005*\"today\" + 0.004*\"get\" + 0.003*\"happy\" + 0.003*\"day\"'),\n (6,\n  '0.007*\"day\" + 0.005*\"thank\" + 0.003*\"think\" + 0.003*\"be\" + 0.003*\"have\" + 0.003*\"team\" + 0.003*\"=\" + 0.003*\"get\" + 0.003*\"hug\" + 0.003*\"tonight\"'),\n (7,\n  '0.007*\"day\" + 0.006*\"love\" + 0.006*\"time\" + 0.005*\"year\" + 0.004*\"think\" + 0.004*\"lot\" + 0.004*\"today\" + 0.004*\"end\" + 0.004*\"amp\" + 0.004*\"president\"'),\n (8,\n  '0.007*\"feel\" + 0.007*\"amp\" + 0.006*\"love\" + 0.005*\"like\" + 0.005*\"get\" + 0.005*\"e\" + 0.005*\"thank\" + 0.004*\"man\" + 0.004*\"be\" + 0.003*\"o\"'),\n (9,\n  '0.009*\"love\" + 0.007*\"be\" + 0.007*\"like\" + 0.006*\"well\" + 0.006*\"time\" + 0.005*\"new\" + 0.004*\"let\" + 0.004*\"sorry\" + 0.004*\"run\" + 0.004*\"mayor\"')]"
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plda.show_topics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Are your topics interpretable/interesting? Sometimes they require a good deal of fine tuning and parameter choosing to get it to work in a nice way. Check out the gensim ldamodel documentation page and see what parameters you can play around with and try the model again!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "outputs": [],
   "source": [
    "for actor in person_network.nodes():\n",
    "    actor_all_words = []\n",
    "    for sent in person_network.nodes[actor]['words']:\n",
    "        for word in sent:\n",
    "            actor_all_words += word\n",
    "    person_network.nodes[actor]['topic_distribution'] = plda[dictionary.doc2bow(lucem_illud_2020.normalizeTokens(actor_all_words))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have topic distributions for each character. Let us have a brief look at what the characters are talking about."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oeBiden [(2, 0.20543511), (3, 0.30083644), (6, 0.12916549), (8, 0.3590384)]\n",
      "tephcrowder [(2, 0.21821709), (3, 0.305211), (4, 0.015591355), (6, 0.13052833), (8, 0.3303626)]\n",
      "izzle [(2, 0.23125535), (3, 0.27639714), (4, 0.034918323), (6, 0.12557352), (8, 0.33155423)]\n",
      "YPETWICE [(2, 0.27092057), (3, 0.21098183), (4, 0.025245197), (6, 0.1084534), (8, 0.36686444), (9, 0.017488843)]\n",
      "lazenTheDragon [(2, 0.17601855), (3, 0.18239245), (4, 0.25967214), (6, 0.100040965), (8, 0.2816637)]\n",
      "ndrewYang [(2, 0.20845363), (3, 0.30506864), (6, 0.13777694), (8, 0.34140536)]\n",
      "iHLSilentH [(2, 0.20029509), (3, 0.32249713), (6, 0.123640485), (8, 0.35332295)]\n",
      "teffieharner [(2, 0.20173696), (3, 0.27701712), (4, 0.018301986), (6, 0.11319987), (8, 0.38590434)]\n",
      "unnySarahphina [(2, 0.19118963), (3, 0.27707458), (6, 0.13853961), (8, 0.39188692)]\n",
      "inoaliceglobal [(2, 0.23060255), (3, 0.28925762), (4, 0.026642838), (6, 0.108812876), (8, 0.34434557)]\n",
      "lyssa_Susanna [(2, 0.3010345), (3, 0.2542301), (4, 0.050274108), (6, 0.12090418), (8, 0.27351478)]\n",
      "tarBoiKeita [(2, 0.24378651), (3, 0.33878374), (6, 0.10511598), (8, 0.30671206)]\n",
      "lexonism [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "otBiForce [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "aaammmz [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "amporsh [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "otcheribow [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "he_Coday [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "annyurru [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "Haarrbb [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "vermorered1989 [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "lexChenault [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "aplinebabie [(0, 0.10062323), (1, 0.096944556), (2, 0.10357546), (3, 0.10479636), (4, 0.10073284), (5, 0.0971624), (6, 0.095099315), (7, 0.099435836), (8, 0.10084943), (9, 0.100780584)]\n",
      "allmeroygbiv [(2, 0.1912413), (3, 0.25649846), (4, 0.011185527), (6, 0.12899643), (8, 0.41175652)]\n",
      "WAmbulance [(2, 0.20518227), (3, 0.29275045), (6, 0.13827474), (8, 0.35489535)]\n",
      "tjohnambulance [(2, 0.19335535), (3, 0.28681883), (6, 0.13034365), (8, 0.38257137)]\n",
      "eaphere [(2, 0.19736713), (3, 0.29636303), (4, 0.016933843), (6, 0.11627823), (8, 0.37131292)]\n"
     ]
    }
   ],
   "source": [
    "for actor in person_network.nodes():\n",
    "    print(actor, person_network.nodes[actor]['topic_distribution'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quickly eye-balling these distributions suggest that the model itself could be tuned better - all the topics are loaded more or less equally.\n",
    "\n",
    "In the paper I linked to earlier, they found similarities or differences using the KL divergence - this is a topic we've dealt with before. Let us plot a heatmap with these values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [],
   "source": [
    "from gensim.matutils import kullback_leibler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [],
   "source": [
    "def convert_to_prob(bow):\n",
    "    ps = []\n",
    "    for topic_no, topic_prob in bow:\n",
    "        ps.append(topic_prob)\n",
    "    return ps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "outputs": [],
   "source": [
    "\n",
    "L = []\n",
    "for actor_1 in person_network.nodes():\n",
    "    p = person_network.nodes[actor_1]['topic_distribution']\n",
    "    p = convert_to_prob(p)\n",
    "    l = []\n",
    "    for actor_2 in person_network.nodes():\n",
    "        q = person_network.nodes[actor_2]['topic_distribution']\n",
    "        q = convert_to_prob(q)\n",
    "        if (len(p) != len(q)):\n",
    "            p = p[:min(len(p), len(q))]\n",
    "            q = q[:min(len(p), len(q))]\n",
    "        l.append(kullback_leibler(p, q))\n",
    "    L.append(l)\n",
    "M = np.array(L)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "div = pandas.DataFrame(M, columns = list(person_network.nodes()), index = list(person_network.nodes()))\n",
    "ax = sns.heatmap(div)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}